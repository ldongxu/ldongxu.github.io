{"meta":{"title":"刘东旭博客","subtitle":"8小时内求生存，8小时外求发展","description":"「人若无名, 便可专心练剑」","author":"刘东旭","url":"https://ldongxu.github.io"},"pages":[{"title":"标签","date":"2017-03-28T03:28:29.000Z","updated":"2018-07-06T12:33:08.045Z","comments":false,"path":"tags/index.html","permalink":"https://ldongxu.github.io/tags/index.html","excerpt":"","text":""},{"title":"关于","date":"2017-03-28T03:24:29.000Z","updated":"2018-07-06T12:33:08.044Z","comments":false,"path":"about/index.html","permalink":"https://ldongxu.github.io/about/index.html","excerpt":"","text":"刘东旭，Java工程师，客居北京。喜欢研究新技术，擅长分布式Web系统，没有JetBrains 全家桶就写不出代码，没有Google和StackOverflow就解决不了技术问题，梦想着有一天江湖留名。曾在某国企从事系统开发及项目管理，后入职互联网公司，参加过多个互联网产品从产品设计到开发上线的完整周期，了解互联网产品交互、设计、开发、测试、上线等完整开发流程。 联系方式邮箱：ldongxu@126.com"},{"title":"分类","date":"2017-03-28T03:22:10.000Z","updated":"2018-07-06T12:33:08.044Z","comments":false,"path":"categories/index.html","permalink":"https://ldongxu.github.io/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"Redis实现分布式同步锁","slug":"Redis实现分布式同步锁","date":"2018-07-19T09:18:05.000Z","updated":"2018-07-19T10:51:51.567Z","comments":true,"path":"2018/07/19/Redis实现分布式同步锁/","link":"","permalink":"https://ldongxu.github.io/2018/07/19/Redis实现分布式同步锁/","excerpt":"现在大多数服务都是分布式部署，分布式环境下需要考虑同步问题时需要用到分布式的同步锁。","text":"现在大多数服务都是分布式部署，分布式环境下需要考虑同步问题时需要用到分布式的同步锁。分布式锁一般有三种实现方式： 数据库乐观锁； 基于Redis的分布式锁； 基于ZooKeeper的分布式锁。 为了确保分布式锁可用，要确保锁的实现满足以下三个条件： 互斥性 不会发生死锁 加锁和解锁必须是同一个客户端 常见的错误的分布式锁Redis实现错误加锁代码：先看两个个加锁代码示例：示例1：1234567public static void wrongGetLock1(Jedis jedis, String lockKey, String val, int expireTime) &#123; Long result = jedis.setnx(lockKey, val); if (result == 1) &#123; // 若在这里程序突然崩溃，则无法设置过期时间，将发生死锁 jedis.expire(lockKey, expireTime); &#125;&#125; 示例1存在的问题：使用jedis.setnx()和jedis.expire()组合实现加锁,setnx()方法作用就是SET IF NOT EXIST，expire()方法就是给锁加一个过期时间。乍一看好像和前面的set()方法结果一样，然而由于这是两条Redis命令，不具有原子性，如果程序在执行完setnx()之后突然崩溃，导致锁没有设置过期时间。那么将会发生死锁。 示例2:123456789101112131415161718192021222324 public synchronized boolean lock() throws InterruptedException &#123; this.locked = false; final long nano = System.currentTimeMillis(); final long timeout = timeoutMillis; while (System.currentTimeMillis() - nano &lt; timeout) &#123; long expireTime = System.currentTimeMillis() + expireMillis + 1; final String expireStr = String.valueOf(expireTime); if (this.setNX(lockKey, expireStr)) &#123; this.locked = true; return true; &#125; String currentValueStr = this.get(lockKey); if (currentValueStr != null &amp;&amp; isExpired(currentValueStr)) &#123; String oldValueStr = this.getSet(lockKey, expireStr); if (oldValueStr != null &amp;&amp; isExpired(oldValueStr)) &#123; this.locked = true; return true; &#125; &#125; //短暂休眠，避免活锁 Thread.sleep(100, random.nextInt(30)); &#125; return false;&#125; 示例2使用jedis.setnx()命令实现加锁，其中key是锁，value是锁的过期时间。执行过程：1. 通过setnx()方法尝试加锁，如果当前锁不存在，返回加锁成功。2. 如果锁已经存在则获取锁的过期时间，和当前时间比较，如果锁已经过期，则设置新的过期时间，返回加锁成功。那么这段代码问题在哪里？1. 由于是客户端自己生成过期时间，所以需要强制要求分布式下每个客户端的时间必须同步。 2. 当锁过期的时候，如果多个客户端同时执行jedis.getSet()方法，那么虽然最终只有一个客户端可以加锁，但是这个客户端的锁的过期时间可能被其他客户端覆盖。3. 锁不具备拥有者标识，即任何客户端都可以解锁。 错误解锁代码：下面看几个错误解锁示例：错误示例1：最常见的解锁代码就是直接使用jedis.del()方法删除锁，这种不先判断锁的拥有者而直接解锁的方式，会导致任何客户端都可以随时进行解锁，即使这把锁不是它的。123public static void wrongReleaseLock1(Jedis jedis, String lockKey) &#123; jedis.del(lockKey);&#125; 错误示例2这种解锁代码乍一看也是没问题，与正确姿势差不多，唯一区别的是分成两条命令去执行，代码如下：12345678public static void wrongReleaseLock2(Jedis jedis, String lockKey, String requestId) &#123; // 判断加锁与解锁是不是同一个客户端 if (requestId.equals(jedis.get(lockKey))) &#123; // 若在此时，这把锁突然不是这个客户端的，则会误解锁 jedis.del(lockKey); &#125;&#125; 如代码注释，问题在于如果调用jedis.del()方法的时候，这把锁已经不属于当前客户端的时候会解除他人加的锁。那么是否真的有这种场景？答案是肯定的，比如客户端A加锁，一段时间之后客户端A解锁，在执行jedis.del()之前，锁突然过期了，此时客户端B尝试加锁成功，然后客户端A再执行del()方法，则将客户端B的锁给解除了。 分布式锁Redis正确实现加锁：1234public boolean trylock()&#123; String result = this.jedis.set(lockKey,requestId,SET_IF_NOT_EXIST,SET_WITH_EXPIRE_TIME_MILLISECONDS,expireTime); return LOCK_SUCCESS.equals(result);&#125; 可以看到，我们加锁就一行代码：jedis.set(String key, String value, String nxxx, String expx, int time)，这个set()方法一共有五个形参： ● 第一个为key，我们使用key来当锁，因为key是唯一的。 ● 第二个为value，我们传的是requestId，很多童鞋可能不明白，有key作为锁不就够了吗，为什么还要用到value？原因就是我们在上面讲到可靠性时，分布式锁要满足第四个条件解铃还须系铃人，通过给value赋值为requestId，我们就知道这把锁是哪个请求加的了，在解锁的时候就可以有依据。requestId可以使用UUID.randomUUID().toString()方法生成。 ● 第三个为nxxx，这个参数我们填的是NX，意思是SET IF NOT EXIST，即当key不存在时，我们进行set操作；若key已经存在，则不做任何操作； ● 第四个为expx，这个参数我们传的是PX，意思是我们要给这个key加一个过期的设置，具体时间由第五个参数决定。 ● 第五个为time，与第四个参数相呼应，代表key的过期时间。 总的来说，执行上面的set()方法就只会导致两种结果： 当前没有锁（key不存在），那么就进行加锁操作，并对锁设置个有效期，同时value表示加锁的客户端。 已有锁存在，不做任何操作。 心细的童鞋就会发现了，我们的加锁代码满足我们可靠性里描述的三个条件。首先，set()加入了NX参数，可以保证如果已有key存在，则函数不会调用成功，也就是只有一个客户端能持有锁，满足互斥性。其次，由于我们对锁设置了过期时间，即使锁的持有者后续发生崩溃而没有解锁，锁也会因为到了过期时间而自动解锁（即key被删除），不会发生死锁。最后，因为我们将value赋值为requestId，代表加锁的客户端请求标识，那么在客户端在解锁的时候就可以进行校验是否是同一个客户端。 解锁有了正确的加锁姿势，看一下正确的解锁姿势：12345public boolean unlock()&#123; String script = \"if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end\"; Object result = this.jedis.eval(script, Collections.singletonList(lockKey), Collections.singletonList(requestId)); return RELEASE_SUCCESS.equals(result);&#125; 我们解锁只需要两行代码就搞定了！第一行代码，我们写了一个简单的Lua脚本代码，第二行代码，我们将Lua代码传到jedis.eval()方法里，并使参数KEYS[1]赋值为lockKey，ARGV[1]赋值为requestId。eval()方法是将Lua代码交给Redis服务端执行。思路是要确保上述操作是原子性的，所以检查和删除在一个命令里执行，首先获取锁对应的value值，检查是否与requestId相等，如果相等则删除锁（解锁）。jedis.eval命令执行Lua代码的候，Lua代码将被当成一个命令去执行，并且直到eval命令执行完成，Redis才会执行其他命令。","categories":[{"name":"Java","slug":"Java","permalink":"https://ldongxu.github.io/categories/Java/"}],"tags":[{"name":"分布式锁","slug":"分布式锁","permalink":"https://ldongxu.github.io/tags/分布式锁/"}]},{"title":"Java并发编程《一》","slug":"Java并发编程《一》","date":"2017-07-10T15:23:13.000Z","updated":"2018-07-06T12:33:08.042Z","comments":true,"path":"2017/07/10/Java并发编程《一》/","link":"","permalink":"https://ldongxu.github.io/2017/07/10/Java并发编程《一》/","excerpt":"对Java并发编程学习已经有段时间了，知识需要系统的学习才能更好的理解，也要勤于整理才不至于学了之后时间一长就模糊，然后实践中多用，该总结的时候还是不能偷懒的。 从事开发时，有时会遇到线程之间的协作问题。obj.wait(),obj.notify()，obj.notifyAll(),t.join(),t.yield()成为了我们进行线程协作的常用方法，他们的区别和原理在网上很容易就可以搜到。本人在从事开发的过程中，数次理清他们之间的关系，但一直没有做过总结整理，时间一长记忆就模糊了。","text":"对Java并发编程学习已经有段时间了，知识需要系统的学习才能更好的理解，也要勤于整理才不至于学了之后时间一长就模糊，然后实践中多用，该总结的时候还是不能偷懒的。 从事开发时，有时会遇到线程之间的协作问题。obj.wait(),obj.notify()，obj.notifyAll(),t.join(),t.yield()成为了我们进行线程协作的常用方法，他们的区别和原理在网上很容易就可以搜到。本人在从事开发的过程中，数次理清他们之间的关系，但一直没有做过总结整理，时间一长记忆就模糊了。 一、Java线程状态： 新建(new)：新创建了一个线程对象。 可运行(runnable)：线程对象创建后，其他线程(比如main线程）调用了该对象的start()方法。该状态的线程位于可运行线程池中，等待被线程调度选中，获取cpu 的使用权 。 运行(running)：可运行状态(runnable)的线程获得了cpu 时间片（timeslice） ，执行程序代码。 阻塞(block)：阻塞状态是指线程因为某种原因放弃了cpu 使用权，也即让出了cpu timeslice，暂时停止运行。直到线程进入可运行(runnable)状态，才有机会再次获得cpu timeslice 转到运行(running)状态。阻塞的情况分三种：(一). 等待阻塞：运行(running)的线程执行o.wait()方法，JVM会把该线程放入等待队列(waitting queue)中。(二). 同步阻塞：运行(running)的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则JVM会把该线程放入锁池(lock pool)中。(三). 其他阻塞：运行(running)的线程执行Thread.sleep(long ms)或t.join()方法，或者发出了I/O请求时，JVM会把该线程置为阻塞状态。当sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入可运行(runnable)状态。 死亡(dead)：线程run()、main() 方法执行结束，或者因异常退出了run()方法，则该线程结束生命周期。死亡的线程不可再次复生。 二、Wait-Notify机制wait,notify,notifyAll在线程同步是我们经常用到，首先要弄清楚一点，这三个方法并不是Thread类的方法，他们是object类的方法。所以Java中一切对象都有这三个方法。 以下我默认使用的是对象锁，类锁也是同样的道理。 （1）wait wait是要释放对象锁，进入等待池。既然是释放对象锁，那么肯定是先要获得锁。所以wait必须要写在synchronized代码块中，否则会报“java.lang.IllegalMonitorStateException”异常。（我们只需牢牢记住，要释放锁，必须要先获得锁。） （2）notify,notifyAllnotify跟notifyAll,作用很相似。他们也需要写在synchronized代码块中，调用对象的这两个方法也需要先获得该对象的锁。notify，notifyAll，唤醒等待该对象同步锁的线程。notify唤醒对象等待池中的任意一个线程，将这个线程放入该对象的锁池中。对象的锁池中线程可以去竞争得到对象锁，然后开始执行。notify去唤醒线程的时候是随机的，没有优先级之分，也不会因为先到就先被唤醒。notifyAll唤醒对象等待池中的所有线程，把这些线程都加到对象的锁池中，让他们去竞争锁。notify，notifyAll调用时并不会释放对象锁。所以，如下代码：12345678910public void test()&#123; Object object = new Object(); synchronized (object)&#123; object.notifyAll(); while (true)&#123; &#125; &#125;&#125; 虽然调用了notifyAll，但是紧接着进入了一个死循环。导致一直不能出临界区，一直不能释放对象锁。所以，即使它把所有在等待池中的线程都唤醒放到了对象的锁池中，但是锁池中的所有线程都不会运行，因为他们都拿不到锁。 对象的等待池，对象的锁池。前面我一直提到两个概念，等待池，锁池。这两者是不一样的。 锁池: 假设线程A已经拥有了某个对象(注意:不是类)的锁，而其它的线程想要调用这个对象的某个synchronized方法(或者synchronized块)，由于这些线程在进入对象的synchronized方法之前必须先获得该对象的锁的拥有权，但是该对象的锁目前正被线程A拥有，所以这些线程就进入了该对象的锁池中。 等待池: 假设一个线程A调用了某个对象的wait()方法，线程A就会释放该对象的锁(因为wait()方法必须出现在synchronized中，这样自然在执行wait()方法之前线程A就已经拥有了该对象的锁)，同时线程A就进入到了该对象的等待池中。如果另外的一个线程调用了相同对象的notifyAll()方法，那么处于该对象的等待池中的线程就会全部进入该对象的锁池中，准备争夺锁的拥有权。如果另外的一个线程调用了相同对象的notify()方法，那么仅仅有一个处于该对象的等待池中的线程(随机)会进入该对象的锁池. 如下代码：1234567891011Object object = new Object();public void test()&#123; synchronized (object)&#123; =======A try &#123; object.wait(); =======B &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 线程1如果卡在A处，那么他会被放入object的锁池。如果在B处调用了wait方法，会释放对象锁，被放入object的等待池。等待其他线程调用了object.notifyAll(),才会被唤醒，放入object的锁池去竞争锁。也就是说，在锁池中才有资格去竞争锁。在等待池中是没有的，只能先等待别人把它唤醒。 三、sleep和wait的区别：1、首先，要记住这个差别，“sleep是Thread类的静态方法,wait是Object类中定义的方法”。尽管这两个方法都会影响线程的执行行为，但是本质上是有区别的。2、Thread.sleep不会导致锁行为的改变，如果当前线程是拥有锁的，那么Thread.sleep不会让线程释放锁，调用Thread.sleep是不会影响锁的相关行为；当一个线程执行到wait()方法时，它就进入到一个和该对象相关的等待池中，同时失去（释放）了对象的机锁（暂时失去机锁，wait(long timeout)超时时间到后还需要返还对象锁）；3、Thread.sleep和Object.wait都会暂停当前的线程，对于CPU资源来说，不管是哪种方式暂停的线程，都表示它暂时不再需要CPU的执行时间。OS会将执行时间分配给其它线程。区别是，调用wait后，需要别的线程执行notify/notifyAll才能够重新获得CPU执行时间。4、wiat()必须放在synchronized block中，否则会在program runtime时扔出”java.lang.IllegalMonitorStateException“异常。 所以sleep()和wait()方法的最大区别是： sleep()睡眠时，保持对象锁，仍然占有该锁； 而wait()睡眠时，释放对象锁。 但是wait()和sleep()都可以通过interrupt()方法打断线程的暂停状态，从而使线程立刻抛出InterruptedException（但不建议使用该方法）。 四、Thread.yield()在Thread.java中yield()定义如下：1234567/** * A hint to the scheduler that the current thread is willing to yield its current use of a processor. The scheduler is free to ignore * this hint. Yield is a heuristic attempt to improve relative progression between threads that would otherwise over-utilize a CPU. * Its use should be combined with detailed profiling and benchmarking to ensure that it actually has the desired effect. */ public static native void yield(); 一个调用yield()方法的线程告诉虚拟机它乐意让其他线程占用自己的位置。这表明该线程没有在做一些紧急的事情。注意，这仅是一个暗示，并不能保证不会产生任何影响。 yield是一个静态的原生(native)方法。 yield告诉当前正在执行的线程把运行机会交给线程池中拥有相同优先级的线程。 yield不能保证使得当前正在运行的线程迅速转换到Runnable状态，它仅能使一个线程从运行状态转到Runnable状态，而不是等待或阻塞状态。 yield方法使用示例：在下面的示例程序中，我随意的创建了名为生产者和消费者的两个线程。生产者设定为最小优先级，消费者设定为最高优先级。在Thread.yield()注释和非注释的情况下分别运行该程序。没有调用yield()方法时，虽然输出有时改变，但是通常消费者行先打印出来，然后事生产者。调用yield()方法时，两个线程依次打印，然后将执行机会交给对方，一直这样进行下去。12345678910111213141516171819202122232425262728293031323334353637383940package test.core.threads; public class YieldExample&#123; public static void main(String[] args) &#123; Thread producer = new Producer(); Thread consumer = new Consumer(); producer.setPriority(Thread.MIN_PRIORITY); //Min Priority consumer.setPriority(Thread.MAX_PRIORITY); //Max Priority producer.start(); consumer.start(); &#125;&#125; class Producer extends Thread&#123; public void run() &#123; for (int i = 0; i &lt; 5; i++) &#123; System.out.println(\"I am Producer : Produced Item \" + i); Thread.yield(); &#125; &#125;&#125; class Consumer extends Thread&#123; public void run() &#123; for (int i = 0; i &lt; 5; i++) &#123; System.out.println(\"I am Consumer : Consumed Item \" + i); Thread.yield(); &#125; &#125;&#125; 上述程序在没有调用yield()方法情况下的输出：12345678910I am Consumer : Consumed Item 0 I am Consumer : Consumed Item 1 I am Consumer : Consumed Item 2 I am Consumer : Consumed Item 3 I am Consumer : Consumed Item 4 I am Producer : Produced Item 0 I am Producer : Produced Item 1 I am Producer : Produced Item 2 I am Producer : Produced Item 3 I am Producer : Produced Item 4 上述程序在调用yield()方法情况下的输出：12345678910I am Producer : Produced Item 0 I am Consumer : Consumed Item 0 I am Producer : Produced Item 1 I am Consumer : Consumed Item 1 I am Producer : Produced Item 2 I am Consumer : Consumed Item 2 I am Producer : Produced Item 3 I am Consumer : Consumed Item 3 I am Producer : Produced Item 4 I am Consumer : Consumed Item 4 五、t.join()线程实例的方法join()方法可以使得一个线程在另一个线程结束后再执行。如果join()方法在一个线程实例上调用，当前运行着的线程将阻塞直到这个线程实例完成了执行。123//Waits for this thread to die. public final void join() throws InterruptedException 在join()方法内设定超时，使得join()方法的影响在特定超时后无效。当超时时，主方法和任务线程申请运行的时候是平等的。然而，当涉及sleep时，join()方法依靠操作系统计时，所以你不应该假定join()方法将会等待你指定的时间。 像sleep,join通过抛出InterruptedException对中断做出回应。 join()方法使用示例1234567891011121314151617181920212223242526272829303132333435363738394041package test.core.threads; public class JoinExample&#123; public static void main(String[] args) throws InterruptedException &#123; Thread t = new Thread(new Runnable() &#123; public void run() &#123; System.out.println(&quot;First task started&quot;); System.out.println(&quot;Sleeping for 2 seconds&quot;); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;First task completed&quot;); &#125; &#125;); Thread t1 = new Thread(new Runnable() &#123; public void run() &#123; System.out.println(&quot;Second task completed&quot;); &#125; &#125;); t.start(); // Line 15 t.join(); // Line 16 t1.start(); &#125;&#125; Output: First task startedSleeping for 2 secondsFirst task completedSecond task completed","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://ldongxu.github.io/tags/Java/"},{"name":"Java并发编程","slug":"Java并发编程","permalink":"https://ldongxu.github.io/tags/Java并发编程/"}]},{"title":"Java单例模式","slug":"Java单例模式","date":"2017-07-04T08:06:34.000Z","updated":"2018-07-06T12:33:08.041Z","comments":true,"path":"2017/07/04/Java单例模式/","link":"","permalink":"https://ldongxu.github.io/2017/07/04/Java单例模式/","excerpt":"单例类可以是没有状态的，一般仅用做提供工具性函数的对象。既然是提供工具性函数，也就没有必要创建多个实例。","text":"单例类可以是没有状态的，一般仅用做提供工具性函数的对象。既然是提供工具性函数，也就没有必要创建多个实例。 Singleton的几种实现方式：一、懒汉式（双重检验锁）123456789101112131415public class Singleton&#123; private volatile static Singleton uniqueInstance=null; private Singleton()&#123;&#125; public static Singleton getInstance()&#123; if(uniqueInstance==null)&#123; synchronized(Singleton.class)&#123; if(uniqueInstance==null)&#123; uniqueInstance=new Singleton(); &#125; &#125; &#125; return uniqueInstance; &#125; //other useful methods here&#125; 这种写法能够在多线程中很好的工作，而且看起来它也具备很好的lazy loading，但是，遗憾的是，效率很低，99%情况下不需要同步。 二、饿汉式1234567public class Singleton&#123; private static Singleton uniqueInstance=new Singleton(); private Singleton()&#123;&#125; public static Singleton getInstance()&#123; return uniqueInstance; &#125;&#125; 种方式基于classloder机制避免了多线程的同步问题，不过，instance在类装载时就实例化，虽然导致类装载的原因有很多种，在单例模式中大多数都是调用getInstance方法，但是也不能确定有其他的方式（或者其他的静态方法）导致类装载，这时候初始化instance显然没有达到lazy loading的效果。 三、静态内部类（线程安全）1234567891011public class Singleton &#123; private static class SingletonHolder &#123; private static final Singleton INSTANCE = new Singleton(); &#125; private Singleton() &#123;&#125; public static final Singleton getInstance() &#123; return SingletonHolder.INSTANCE; &#125;&#125; 这种方式是Singleton类被装载了，instance不一定被初始化。因为SingletonHolder类没有被主动使用，只有显示通过调用getInstance方法时，才会显式装载SingletonHolder类，实例化instance，从而达到lazy loading效果，同时根据JVM本身机制，静态内部类的加载能够保证线程安全。 四、枚举法以上方式存在两种创建新实例的风险，一是通过反射机制调用私有构造器，二是通过反序列化一个序列化的实例。 在《Effective Java》推荐了这样一个写法，它更加简洁，而且保证了线程安全。此方法无偿提供了序列化机制，绝对防止多次实例化，即使面对复杂的序列化或者反射攻击。单元素枚举类型已经成为实现Singleton的最佳方法。12345public enum Singleton &#123; INSTANCE; public void execute()&#123;...&#125;&#125; 很多人会对枚举法实现的单例模式很不理解。这里需要深入理解的是两个点： 枚举类实现其实省略了private类型的构造函数 枚举类的域(field)其实是相应的enum类型的一个实例对象 对于第一点实际上enum内部是如下代码:12345public enum Singleton &#123; INSTANCE; // 这里隐藏了一个空的私有构造方法 private Singleton () &#123;&#125;&#125; 单元素的枚举类型实现Singleton.Java枚举类型背后的基本想法：通过公有的静态final域为每个枚举常量导出实例的类。因为没有可访问的构造器，枚举类型是真正的final。因为客户端既不能创建枚举类型实例，也不能对它进行扩张，因此很可能没有实例，而只有声明过的枚举常量。换句话说，枚举类型是实例受控的，是单例的泛型化，本质上是单元素的枚举 -《Effective Java》 对于一个标准的enum单例模式，更好的写法还是实现接口的形式:1234567891011121314151617// 定义单例模式中需要完成的代码逻辑public interface MySingleton &#123; void doSomething();&#125;public enum Singleton implements MySingleton &#123; INSTANCE &#123; @Override public void doSomething() &#123; System.out.println(&quot;complete singleton&quot;); &#125; &#125;; public static MySingleton getInstance() &#123; return Singleton.INSTANCE; &#125;&#125;","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://ldongxu.github.io/tags/Java/"},{"name":"单例模式","slug":"单例模式","permalink":"https://ldongxu.github.io/tags/单例模式/"}]},{"title":"Java阻塞队列-BlockingQueue","slug":"Java阻塞队列-BlockingQueue","date":"2017-06-15T04:30:24.000Z","updated":"2018-07-06T12:33:08.042Z","comments":true,"path":"2017/06/15/Java阻塞队列-BlockingQueue/","link":"","permalink":"https://ldongxu.github.io/2017/06/15/Java阻塞队列-BlockingQueue/","excerpt":"队列是一种数据结构。它有两个基本操作：在队列尾部加入一个元素和从队列头部移除一个元素。就是说，队列以一种先进先出的方式管理数据（FIFO (first-in-first-out)），如果你试图向一个已经满了的阻塞队列中添加一个元素或者是从一个空的阻塞队列中移除一个元索，将导致线程阻塞。在多线程进行合作时，阻塞队列是很有用的工具。工作者线程可以定期地把中间结果存到阻塞队列中而其他工作者线线程把中间结果取出并在将来修改它们。队列会自动平衡负载。如果第一个线程集运行得比第二个慢，则第二个线程集在等待结果时就会阻塞。如果第一个线程集运行得快，那么它将等待第二个线程集赶上来。","text":"队列是一种数据结构。它有两个基本操作：在队列尾部加入一个元素和从队列头部移除一个元素。就是说，队列以一种先进先出的方式管理数据（FIFO (first-in-first-out)），如果你试图向一个已经满了的阻塞队列中添加一个元素或者是从一个空的阻塞队列中移除一个元索，将导致线程阻塞。在多线程进行合作时，阻塞队列是很有用的工具。工作者线程可以定期地把中间结果存到阻塞队列中而其他工作者线线程把中间结果取出并在将来修改它们。队列会自动平衡负载。如果第一个线程集运行得比第二个慢，则第二个线程集在等待结果时就会阻塞。如果第一个线程集运行得快，那么它将等待第二个线程集赶上来。Queue接口与List、Set同一级别，都是继承了Collection接口。LinkedList实现了Queue接 口。Queue接口窄化了对LinkedList的方法的访问权限（即在方法中的参数类型如果是Queue时，就完全只能访问Queue接口所定义的方法了，而不能直接访问LinkedList的非Queue的方法），以使得只有恰当的方法才可以使用。 队列 Queue首先看一下java.util下的Queue接口定义：12345678910111213141516171819202122232425262728293031package java.util;/** * &lt;p&gt;This interface is a member of the Java Collections Framework. * * @see java.util.Collection * @see LinkedList * @see PriorityQueue * @see java.util.concurrent.LinkedBlockingQueue * @see java.util.concurrent.BlockingQueue * @see java.util.concurrent.ArrayBlockingQueue * @see java.util.concurrent.LinkedBlockingQueue * @see java.util.concurrent.PriorityBlockingQueue * @since 1.5 * @author Doug Lea * @param &lt;E&gt; the type of elements held in this collection */public interface Queue&lt;E&gt; extends Collection&lt;E&gt; &#123; boolean add(E e); boolean offer(E e); E remove(); E poll(); E element(); E peek();&#125; 除了基本的继承了java.util.Collection的操作之外，队列提供额外的插入、提取和查找操作。这些方法中的每一种都有两种形式：一种是如果操作失败则抛出一个异常，另一个返回一个特殊的值（null或false），具体取决于操作）。后一种形式的插入操作设计，专门用于容量限制实现;（在大多数实现中，插入操作不能失败。） Queue接口继承了java.util.Collection，Queue接口方法概要： 方法 抛出异常 返回特定值 说明 插入 add(e) offer(e) add(e)如果队列已满，则抛出一个IIIegaISlabEepeplian异常；offer(e)如果队列已满返回false，否则返回true 移除 remove() poll() remove()移除并返回队列头部的元素。如果队列为空，则抛出一个NoSuchElementException；poll()移除并返问队列头部的元素。如果队列为空，则返回null 查找 element() peek() element()返回队列头部的元素。如果队列为空，则抛出一个NoSuchElementException；peek()返回队列头部的元素。如果队列为空，则返回null 阻塞队列 BlockingQueue 阻塞队列 (BlockingQueue)是java.util.concurrent包下重要的数据结构，BlockingQueue继承了Queue接口。BlockingQueue提供了线程安全的队列访问方式：当阻塞队列进行插入数据时，如果队列已满，线程将会阻塞等待直到队列非满；从阻塞队列取数据时，如果队列已空，线程将会阻塞等待直到队列非空。并发包下很多高级同步类的实现都是基于BlockingQueue实现的。 阻塞队列 (BlockingQueue接口)在Queue接口的基础上增加了阻塞操作put和take。put方法在队列满时阻塞，take方法在队列空时阻塞。并且带超时的offer和poll方法变种：例如，下面的调用：boolean success = q.offer(x,100,TimeUnit.MILLISECONDS);尝试在100毫秒内向队列尾部插入一个元素。如果成功，立即返回true；否则，当到达超时进，返回false。同样地，调用：Object head = q.poll(100, TimeUnit.MILLISECONDS);如果在100毫秒内成功地移除了队列头元素，则立即返回头元素；否则在到达超时时，返回null。 BlockingQueue是个接口，你需要使用它的实现之一来使用BlockingQueue，Java.util.concurrent包下具有以下 BlockingQueue 接口的实现类： ArrayBlockingQueue：ArrayBlockingQueue 是一个有界的阻塞队列，其内部实现是将对象放到一个数组里。有界也就意味着，它不能够存储无限多数量的元素。它有一个同一时间能够存储元素数量的上限。你可以在对其初始化的时候设定这个上限，但之后就无法对这个上限进行修改了(译者注：因为它是基于数组实现的，也就具有数组的特性：一旦初始化，大小就无法修改)。 DelayQueue：DelayQueue 对元素进行持有直到一个特定的延迟到期。注入其中的元素必须实现 java.util.concurrent.Delayed 接口。 LinkedBlockingQueue：LinkedBlockingQueue 内部以一个链式结构(链接节点)对其元素进行存储。如果需要的话，这一链式结构可以选择一个上限。如果没有定义上限，将使用 Integer.MAX_VALUE 作为上限。 PriorityBlockingQueue：PriorityBlockingQueue 是一个无界的并发队列。它使用了和类java.util.PriorityQueue一样的排序规则。你无法向这个队列中插入null值。所有插入到PriorityBlockingQueue 的元素必须实现 java.lang.Comparable 接口。因此该队列中元素的排序就取决于你自己的 Comparable 实现。 SynchronousQueue：SynchronousQueue 是一个特殊的队列，它的内部同时只能够容纳单个元素。如果该队列已有一元素的话，试图向队列中插入一个新元素的线程将会阻塞，直到另一个线程将该元素从队列中抽走。同样，如果该队列为空，试图向队列中抽取一个元素的线程将会阻塞，直到另一个线程向队列中插入了一条新的元素。据此，把这个类称作一个队列显然是夸大其词了。它更多像是一个汇合点。","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://ldongxu.github.io/tags/Java/"},{"name":"Java队列","slug":"Java队列","permalink":"https://ldongxu.github.io/tags/Java队列/"},{"name":"Queue","slug":"Queue","permalink":"https://ldongxu.github.io/tags/Queue/"}]},{"title":"Java中System.getProperties()和System.getenv()的区别","slug":"Java中System-getProperties-和System-getenv-的区别","date":"2017-06-08T06:36:09.000Z","updated":"2018-07-06T12:33:08.040Z","comments":true,"path":"2017/06/08/Java中System-getProperties-和System-getenv-的区别/","link":"","permalink":"https://ldongxu.github.io/2017/06/08/Java中System-getProperties-和System-getenv-的区别/","excerpt":"System.getenv()是获取系统环境变量，System.getProperty()是获取当前系统相关属性信息。","text":"System.getenv()是获取系统环境变量，System.getProperty()是获取当前系统相关属性信息。 System.getenv()方法JDK中的说明： Returns an unmodifiable string map view of the current system environment.The environment is a system-dependent mapping from names to values which is passed from parent to child processes. 返回当前系统环境的字符串Map。环境是名称对从父进程传递到子进程的值的系统相关映射。 等于在Linux系统下执行：evn命令。 xxxMacBook-Air:~ xxx$ env TERM_PROGRAM=Apple_Terminal SHELL=/bin/bash TERM=xterm-256color TMPDIR=/var/folders/4l/lmg0v7813rl7k731njjt3tlh0000gn/T/ Apple_PubSub_Socket_Render=/private/tmp/com.apple.launchd.8uZ86VHyIp/Render TERM_PROGRAM_VERSION=388.1 TERM_SESSION_ID=2521885E-908A-4F63-8096-A42727205AA8 USER=ldongxu SSH_AUTH_SOCK=/private/tmp/com.apple.launchd.BVRB0zu2xV/Listeners __CF_USER_TEXT_ENCODING=0x1F5:0x19:0x34 PATH=/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/apache-maven-3.5.0/bin:/usr/local/zookeeper-3.4.10/bin JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_131.jdk/Contents/Home/ LANG=zh_CN.UTF-8 XPC_FLAGS=0x0 XPC_SERVICE_NAME=0 M2_HOME=/usr/local/apache-maven-3.5.0 SHLVL=1 HOME=/Users/xxx Z_HOME=/usr/local/zookeeper-3.4.10 LOGNAME=xxx DISPLAY=/private/tmp/com.apple.launchd.QX7X8x0y77/org.macosforge.xquartz:0 在windows中‘系统属性’-&gt;‘高级’-&gt;‘环境变量’； System.getProperty()方法获取系统相关属性，比如：Java版本、操作系统信息、用户名等，这些跟jvm和操作系统相关属性。JDK中说明： Determines the current system properties. 它可获取的一些属性如下： key 说明 java.version Java 运行时环境版本 java.vendor Java 运行时环境供应商 java.vendor.url Java 供应商的 URL java.home Java 安装目录 java.vm.specification.version Java 虚拟机规范版本 java.vm.specification.vendor Java 虚拟机规范供应商 java.vm.specification.name Java 虚拟机规范名称 java.vm.version Java 虚拟机实现版本 java.vm.vendor Java 虚拟机实现供应商 java.vm.name Java 虚拟机实现名称 java.specification.version Java 运行时环境规范版本 java.specification.vendor Java 运行时环境规范供应商 java.specification.name Java 运行时环境规范名称 java.class.version Java 类格式版本号 java.class.path Java 类路径 java.library.path 加载库时搜索的路径列表 java.io.tmpdir 默认的临时文件路径 java.compiler 要使用的 JIT 编译器的名称 java.ext.dirs 一个或多个扩展目录的路径 os.name 操作系统的名称 os.arch 操作系统的架构 file.separator 文件分隔符（在 UNIX 系统中是“/”） path.separator 路径分隔符（在 UNIX 系统中是“:”） line.separator 行分隔符（在 UNIX 系统中是“/n”） user.name 用户的账户名称 user.home 用户的主目录 user.dir 用户的当前工作目录","categories":[{"name":"Java","slug":"Java","permalink":"https://ldongxu.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://ldongxu.github.io/tags/Java/"}]},{"title":"Java代码块","slug":"Java代码块","date":"2017-06-05T08:09:54.000Z","updated":"2018-07-06T12:33:08.041Z","comments":true,"path":"2017/06/05/Java代码块/","link":"","permalink":"https://ldongxu.github.io/2017/06/05/Java代码块/","excerpt":"在编程过程中我们可能会遇到如下这种形式的程序： public class Test { { //// } } 这种形式的程序段我们将其称之为代码块，所谓代码块就是用大括号({})将多行代码封装在一起，形成一个独立的数据体，用于实现特定的算法。一般来说代码块是不能单独运行的，它必须要有运行主体。","text":"在编程过程中我们可能会遇到如下这种形式的程序： public class Test { { //// } } 这种形式的程序段我们将其称之为代码块，所谓代码块就是用大括号({})将多行代码封装在一起，形成一个独立的数据体，用于实现特定的算法。一般来说代码块是不能单独运行的，它必须要有运行主体。在 Java 中代码块主要分为四种： 一、普通代码块普通代码块是我们用得最多的也是最普遍的，它就是在方法名后面用{}括起来的代码段。普通代码块是不能够单独存在的，它必须要紧跟在方法名后面。同时也必须要使用方法名调用它。 public class Test { public void test(){ System.out.println(&quot;普通代码块&quot;); } } 二、静态代码块想到静态我们就会想到 static，静态代码块就是用 static 修饰的用{}括起来的代码段，它的主要目的就是对静态属性进行初始化。 public class Test { static{ System.out.println(&quot;静态代码块&quot;); } } 三、同步代码块使用 synchronized 关键字修饰，并使用“{}”括起来的代码片段，它表示同一时间只能有一个线程进入到该方法块中，是一种多线程保护机制。 四、 构造代码块在类中直接定义没有任何修饰符、前缀、后缀的代码块即为构造代码块。我们明白一个类必须至少有一个构造函数，构造函数在生成对象时被调用。构造代码块和构造函数一样同样是在生成一个对象时被调用，那么构造代码在什么时候被调用？如何调用的呢？看如下代码： public class Test { /** * 构造代码 */ { System.out.println(&quot;执行构造代码块...&quot;); } /** * 无参构造函数 */ public Test(){ System.out.println(&quot;执行无参构造函数...&quot;); } /** * 有参构造函数 * @param id id */ public Test(String id){ System.out.println(&quot;执行有参构造函数...&quot;); } } 上面定义了一个非常简单的类，该类包含无参构造函数、有参构造函数以及构造代码块，同时在上面也提过代码块是没有独立运行的能力，他必须要有一个可以承载的载体，那么编译器会如何来处理构造代码块呢？编译器会将代码块按照他们的顺序(假如有多个代码块)插入到所有的构造函数的最前端，这样就能保证不管调用哪个构造函数都会执行所有的构造代码块。上面代码等同于如下形式： public class Test { /** * 无参构造函数 */ public Test(){ System.out.println(&quot;执行构造代码块...&quot;); System.out.println(&quot;执行无参构造函数...&quot;); } /** * 有参构造函数 * @param id id */ public Test(String id){ System.out.println(&quot;执行构造代码块...&quot;); System.out.println(&quot;执行有参构造函数...&quot;); } } 运行结果 public static void main(String[] args) { new Test(); System.out.println(&quot;----------------&quot;); new Test(&quot;1&quot;); } ------------ Output: 执行构造代码块... 执行无参构造函数... ---------------- 执行构造代码块... 执行有参构造函数... 从上面的运行结果可以看出在 new 一个对象的时候总是先执行构造代码，再执行构造函数，但是有一点需要注意构造代码不是在构造函数之前运行的，它是依托构造函数执行的。正是由于构造代码块有这几个特性，所以它常用于如下场景： 1、初始化实例变量如果一个类中存在若干个构造函数，这些构造函数都需要对实例变量进行初始化，如果我们直接在构造函数中实例化，必定会产生很多重复代码，繁琐和可读性差。这里我们可以充分利用构造代码块来实现。这是利用编译器会将构造代码块添加到每个构造函数中的特性。 2、初始化实例环境一个对象必须在适当的场景下才能存在，如果没有适当的场景，则就需要在创建对象时创建此场景。我们可以利用构造代码块来创建此场景，尤其是该场景的创建过程较为复杂。构造代码会在构造函数之前执行。 上面两个常用场景都充分利用构造代码块的特性，能够很好的解决在实例化对象时构造函数比较难解决的问题，利用构造代码不仅可以减少代码量，同时也是程序的可读性增强了。特别是当一个对象的创建过程比较复杂，需要实现一些复杂逻辑，这个时候如果在构造函数中实现逻辑，这是不推荐的，因为我们提倡构造函数要尽可能的简单易懂，所以我们可以使用构造代码封装这些逻辑实现部分。 五、 静态代码块、构造代码块、构造函数执行顺序从词面上我们就可以看出他们的区别。静态代码块，静态，其作用级别为类，构造代码块、构造函数，构造，其作用级别为对象。 1、静态代码块，它是随着类的加载而被执行，只要类被加载了就会执行，而且只会加载一次，主要用于给类进行初始化。 2、构造代码块，每创建一个对象时就会执行一次，且优先于构造函数，主要用于初始化不同对象共性的初始化内容和初始化实例环境。 3、构造函数，每创建一个对象时就会执行一次。同时构造函数是给特定对象进行初始化，而构造代码是给所有对象进行初始化，作用区域不同。 通过上面的分析，他们三者的执行顺序应该为：静态代码块 &gt; 构造代码块 &gt; 构造函数。 public class Test { /** * 静态代码块 */ static{ System.out.println(&quot;执行静态代码块...&quot;); } /** * 构造代码块 */ { System.out.println(&quot;执行构造代码块...&quot;); } /** * 无参构造函数 */ public Test(){ System.out.println(&quot;执行无参构造函数...&quot;); } /** * 有参构造函数 * @param id */ public Test(String id){ System.out.println(&quot;执行有参构造函数...&quot;); } public static void main(String[] args) { System.out.println(&quot;----------------------&quot;); new Test(); System.out.println(&quot;----------------------&quot;); new Test(&quot;1&quot;); } } ----------- Output: 执行静态代码块... ---------------------- 执行构造代码块... 执行无参构造函数... ---------------------- 执行构造代码块... 执行有参构造函数... 原文：http://wiki.jikexueyuan.com/project/java-enhancement/java-twelve.html","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://ldongxu.github.io/tags/Java/"},{"name":"代码块","slug":"代码块","permalink":"https://ldongxu.github.io/tags/代码块/"}]},{"title":"使用序列化实现对象的拷贝","slug":"使用序列化实现对象的拷贝","date":"2017-06-05T06:57:27.000Z","updated":"2018-07-06T12:33:08.043Z","comments":true,"path":"2017/06/05/使用序列化实现对象的拷贝/","link":"","permalink":"https://ldongxu.github.io/2017/06/05/使用序列化实现对象的拷贝/","excerpt":"我们知道在 Java 中存在这个接口 Cloneable，实现该接口的类都会具备被拷贝的能力，同时拷贝是在内存中进行，在性能方面比我们直接通过 new 生成对象来的快，特别是在大对象的生成上，使得性能的提升非常明显。然而我们知道拷贝分为深拷贝和浅拷贝之分，但是浅拷贝存在对象属性拷贝不彻底问题。关于深拷贝、浅拷贝的请参考这里：渐析 java 的浅拷贝和深拷贝","text":"我们知道在 Java 中存在这个接口 Cloneable，实现该接口的类都会具备被拷贝的能力，同时拷贝是在内存中进行，在性能方面比我们直接通过 new 生成对象来的快，特别是在大对象的生成上，使得性能的提升非常明显。然而我们知道拷贝分为深拷贝和浅拷贝之分，但是浅拷贝存在对象属性拷贝不彻底问题。关于深拷贝、浅拷贝的请参考这里：渐析 java 的浅拷贝和深拷贝 一、浅拷贝问题我们先看如下代码： public class Person implements Cloneable{ /** 姓名 **/ private String name; /** 电子邮件 **/ private Email email; public String getName() { return name; } public void setName(String name) { this.name = name; } public Email getEmail() { return email; } public void setEmail(Email email) { this.email = email; } public Person(String name,Email email){ this.name = name; this.email = email; } public Person(String name){ this.name = name; } protected Person clone() { Person person = null; try { person = (Person) super.clone(); } catch (CloneNotSupportedException e) { e.printStackTrace(); } return person; } } public class Client { public static void main(String[] args) { //写封邮件 Email email = new Email(&quot;请参加会议&quot;,&quot;请与今天12:30到二会议室参加会议...&quot;); Person person1 = new Person(&quot;张三&quot;,email); Person person2 = person1.clone(); person2.setName(&quot;李四&quot;); Person person3 = person1.clone(); person3.setName(&quot;王五&quot;); System.out.println(person1.getName() + &quot;的邮件内容是：&quot; + person1.getEmail().getContent()); System.out.println(person2.getName() + &quot;的邮件内容是：&quot; + person2.getEmail().getContent()); System.out.println(person3.getName() + &quot;的邮件内容是：&quot; + person3.getEmail().getContent()); } } -------------------- Output: 张三的邮件内容是：请与今天12:30到二会议室参加会议... 李四的邮件内容是：请与今天12:30到二会议室参加会议... 王五的邮件内容是：请与今天12:30到二会议室参加会议... 在该应用程序中，首先定义一封邮件，然后将该邮件发给张三、李四、王五三个人，由于他们是使用相同的邮件，并且仅有名字不同，所以使用张三该对象类拷贝李四、王五对象然后更改下名字即可。程序一直到这里都没有错，但是如果我们需要张三提前 30 分钟到，即把邮件的内容修改下： public class Client { public static void main(String[] args) { //写封邮件 Email email = new Email(&quot;请参加会议&quot;,&quot;请与今天12:30到二会议室参加会议...&quot;); Person person1 = new Person(&quot;张三&quot;,email); Person person2 = person1.clone(); person2.setName(&quot;李四&quot;); Person person3 = person1.clone(); person3.setName(&quot;王五&quot;); person1.getEmail().setContent(&quot;请与今天12:00到二会议室参加会议...&quot;); System.out.println(person1.getName() + &quot;的邮件内容是：&quot; + person1.getEmail().getContent()); System.out.println(person2.getName() + &quot;的邮件内容是：&quot; + person2.getEmail().getContent()); System.out.println(person3.getName() + &quot;的邮件内容是：&quot; + person3.getEmail().getContent()); } } 在这里同样是使用张三该对象实现对李四、王五拷贝，最后将张三的邮件内容改变为：请与今天 12:00 到二会议室参加会议…。但是结果是： 张三的邮件内容是：请与今天12:00到二会议室参加会议... 李四的邮件内容是：请与今天12:00到二会议室参加会议... 王五的邮件内容是：请与今天12:00到二会议室参加会议... 这里我们就疑惑了为什么李四和王五的邮件内容也发送了改变呢？让他们提前30分钟到人家会有意见的！ 其实出现问题的关键就在于 clone() 方法上，我们知道该 clone() 方法是使用 Object 类的 clone() 方法，但是该方法存在一个缺陷，它并不会将对象的所有属性全部拷贝过来，而是有选择性的拷贝，基本规则如下： 1、基本类型 如果变量是基本很类型，则拷贝其值，比如 int、float 等。 2、对象 如果变量是一个实例对象，则拷贝其地址引用，也就是说此时新对象与原来对象是公用该实例变量。 3、String 字符串 若变量为 String 字符串，则拷贝其地址引用。但是在修改时，它会从字符串池中重新生成一个新的字符串，原有字符串对象保持不变。 基于上面上面的规则，我们很容易发现问题的所在，他们三者公用一个对象，张三修改了该邮件内容，则李四和王五也会修改，所以才会出现上面的情况。对于这种情况我们还是可以解决的，只需要在 clone() 方法里面新建一个对象，然后张三引用该对象即可： protected Person clone() { Person person = null; try { person = (Person) super.clone(); person.setEmail(new Email(person.getEmail().getObject(),person.getEmail().getContent())); } catch (CloneNotSupportedException e) { e.printStackTrace(); } return person; } 所以：浅拷贝只是 Java 提供的一种简单的拷贝机制，不便于直接使用。 对于上面的解决方案还是存在一个问题，若我们系统中存在大量的对象是通过拷贝生成的，如果我们每一个类都写一个 clone() 方法，并将还需要进行深拷贝，新建大量的对象，这个工程是非常大的，这里我们可以利用序列化来实现对象的拷贝。 二、利用序列化实现对象的拷贝如何利用序列化来完成对象的拷贝呢？在内存中通过字节流的拷贝是比较容易实现的。把母对象写入到一个字节流中，再从字节流中将其读出来，这样就可以创建一个新的对象了，并且该新对象与母对象之间并不存在引用共享的问题，真正实现对象的深拷贝。 public class CloneUtils { @SuppressWarnings(&quot;unchecked&quot;) public static &lt;T extends Serializable&gt; T clone(T obj){ T cloneObj = null; try { //写入字节流 ByteArrayOutputStream out = new ByteArrayOutputStream(); ObjectOutputStream obs = new ObjectOutputStream(out); obs.writeObject(obj); obs.close(); //分配内存，写入原始对象，生成新对象 ByteArrayInputStream ios = new ByteArrayInputStream(out.toByteArray()); ObjectInputStream ois = new ObjectInputStream(ios); //返回生成的新对象 cloneObj = (T) ois.readObject(); ois.close(); } catch (Exception e) { e.printStackTrace(); } return cloneObj; } } 使用该工具类的对象必须要实现 Serializable 接口，否则是没有办法实现克隆的。 public class Person implements Serializable{ private static final long serialVersionUID = 2631590509760908280L; .................. //去除clone()方法 } public class Email implements Serializable{ private static final long serialVersionUID = 1267293988171991494L; .................... } 所以使用该工具类的对象只要实现 Serializable 接口就可实现对象的克隆，无须继承 Cloneable 接口实现 clone() 方法。 public class Client { public static void main(String[] args) { //写封邮件 Email email = new Email(&quot;请参加会议&quot;,&quot;请与今天12:30到二会议室参加会议...&quot;); Person person1 = new Person(&quot;张三&quot;,email); Person person2 = CloneUtils.clone(person1); person2.setName(&quot;李四&quot;); Person person3 = CloneUtils.clone(person1); person3.setName(&quot;王五&quot;); person1.getEmail().setContent(&quot;请与今天12:00到二会议室参加会议...&quot;); System.out.println(person1.getName() + &quot;的邮件内容是：&quot; + person1.getEmail().getContent()); System.out.println(person2.getName() + &quot;的邮件内容是：&quot; + person2.getEmail().getContent()); System.out.println(person3.getName() + &quot;的邮件内容是：&quot; + person3.getEmail().getContent()); } } ------------------- Output: 张三的邮件内容是：请与今天12:00到二会议室参加会议... 李四的邮件内容是：请与今天12:30到二会议室参加会议... 王五的邮件内容是：请与今天12:30到二会议室参加会议...","categories":[{"name":"Java","slug":"Java","permalink":"https://ldongxu.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://ldongxu.github.io/tags/Java/"}]},{"title":"Java 集合细节（三）：subList 的缺陷","slug":"Java-集合细节（三）：subList-的缺陷","date":"2017-06-02T10:32:24.000Z","updated":"2018-07-06T12:33:08.040Z","comments":true,"path":"2017/06/02/Java-集合细节（三）：subList-的缺陷/","link":"","permalink":"https://ldongxu.github.io/2017/06/02/Java-集合细节（三）：subList-的缺陷/","excerpt":"我们经常使用 subString 方法来对 String 对象进行分割处理，同时我们也可以使用 subList、subMap、subSet 来对 List、Map、Set 进行分割处理，但是这个分割存在某些瑕疵。","text":"我们经常使用 subString 方法来对 String 对象进行分割处理，同时我们也可以使用 subList、subMap、subSet 来对 List、Map、Set 进行分割处理，但是这个分割存在某些瑕疵。 一、subList 返回仅仅只是一个视图首先我们先看如下实例： public static void main(String[] args) { List&lt;Integer&gt; list1 = new ArrayList&lt;Integer&gt; (); list1.add(1); list1.add(2); //通过构造函数新建一个包含list1的列表 list2 List&lt;Integer&gt; list2 = new ArrayList&lt;Integer&gt;(list1); //通过subList生成一个与list1一样的列表 list3 List&lt;Integer&gt; list3 = list1.subList(0, list1.size()); //修改list3 list3.add(3); System.out.println(&quot;list1 == list2：&quot; + list1.equals(list2)); System.out.println(&quot;list1 == list3：&quot; + list1.equals(list3)); } 这个例子非常简单，无非就是通过构造函数、subList 重新生成一个与 list1 一样的 list，然后修改 list3，最后比较 list1 == list2?、list1 == list3?。按照我们常规的思路应该是这样的：因为 list3 通过 add 新增了一个元素，那么它肯定与 list1 不等，而 list2 是通过 list1 构造出来的，所以应该相等，所以结果应该是： list1 == list2：true list1 == list3: false 首先我们先不论结果的正确与否，我们先看 subList 的源码： public List&lt;E&gt; subList(int fromIndex, int toIndex) { subListRangeCheck(fromIndex, toIndex, size); return new SubList(this, 0, fromIndex, toIndex); } subListRangeCheck 方式是判断 fromIndex、toIndex 是否合法，如果合法就直接返回一个 subList 对象，注意在产生该 new 该对象的时候传递了一个参数 this ，该参数非常重要，因为他代表着原始 list。 /** * 继承AbstractList类，实现RandomAccess接口 */ private class SubList extends AbstractList&lt;E&gt; implements RandomAccess { private final AbstractList&lt;E&gt; parent; //列表 private final int parentOffset; private final int offset; int size; //构造函数 SubList(AbstractList&lt;E&gt; parent, int offset, int fromIndex, int toIndex) { this.parent = parent; this.parentOffset = fromIndex; this.offset = offset + fromIndex; this.size = toIndex - fromIndex; this.modCount = ArrayList.this.modCount; } //set方法 public E set(int index, E e) { rangeCheck(index); checkForComodification(); E oldValue = ArrayList.this.elementData(offset + index); ArrayList.this.elementData[offset + index] = e; return oldValue; } //get方法 public E get(int index) { rangeCheck(index); checkForComodification(); return ArrayList.this.elementData(offset + index); } //add方法 public void add(int index, E e) { rangeCheckForAdd(index); checkForComodification(); parent.add(parentOffset + index, e); this.modCount = parent.modCount; this.size++; } //remove方法 public E remove(int index) { rangeCheck(index); checkForComodification(); E result = parent.remove(parentOffset + index); this.modCount = parent.modCount; this.size--; return result; } } 该 SubLsit 是 ArrayList 的内部类，它与 ArrayList 一样，都是继承 AbstractList 和实现 RandomAccess 接口。同时也提供了 get、set、add、remove 等 list 常用的方法。但是它的构造函数有点特殊，在该构造函数中有两个地方需要注意： 1、this.parent = parent;而 parent 就是在前面传递过来的 list，也就是说 this.parent 就是原始 list 的引用。 2、this.offset = offset + fromIndex;this.parentOffset = fromIndex;。同时在构造函数中它甚至将 modCount（fail-fast机制）传递过来了。 我们再看 get 方法，在 get 方法中 return ArrayList.this.elementData(offset + index);这段代码可以清晰表明 get 所返回就是原列表 offset + index位置的元素。同样的道理还有 add 方法里面的： parent.add(parentOffset + index, e); this.modCount = parent.modCount; remove 方法里面的 E result = parent.remove(parentOffset + index); this.modCount = parent.modCount; 诚然，到了这里我们可以判断 subList 返回的 SubList 同样也是 AbstractList 的子类，同时它的方法如 get、set、add、remove 等都是在原列表上面做操作，它并没有像 subString 一样生成一个新的对象。所以 subList 返回的只是原列表的一个视图，它所有的操作最终都会作用在原列表上。 那么从这里的分析我们可以得出上面的结果应该恰恰与我们上面的答案相反： list1 == list2：false list1 == list3：true subList 返回的只是原列表的一个视图，它所有的操作最终都会作用在原列表上 二、subList 生成子列表后，不要试图去操作原列表从上面我们知道 subList 生成的子列表只是原列表的一个视图而已，如果我们操作子列表它产生的作用都会在原列表上面表现，但是如果我们操作原列表会产生什么情况呢？ public static void main(String[] args) { List&lt;Integer&gt; list1 = new ArrayList&lt;Integer&gt;(); list1.add(1); list1.add(2); //通过subList生成一个与list1一样的列表 list3 List&lt;Integer&gt; list3 = list1.subList(0, list1.size()); //修改list3 list1.add(3); System.out.println(&quot;list1&apos;size：&quot; + list1.size()); System.out.println(&quot;list3&apos;size：&quot; + list3.size ()); } 该实例如果不产生意外，那么他们两个 list 的大小都应该都是 3，但是偏偏事与愿违，事实上我们得到的结果是这样的： list1&apos;size：3 Exception in thread &quot;main&quot; java.util.ConcurrentModificationException at java.util.ArrayList$SubList.checkForComodification(Unknown Source) at java.util.ArrayList$SubList.size(Unknown Source) at com.chenssy.test.arrayList.SubListTest.main(SubListTest.java:17) list1 正常输出，但是 list3 就抛出 ConcurrentModificationException 异常，就是 fail-fast 机制，（更多请点这里：Java 提高篇（三四）—–fail-fast 机制 ）。我们再看 size 方法： public int size() { checkForComodification(); return this.size; } size 方法首先会通过 checkForComodification 验证，然后再返回this.size。 private void checkForComodification() { if (ArrayList.this.modCount != this.modCount) throw new ConcurrentModificationException(); } 该方法表明当原列表的 modCount 与 this.modCount 不相等时就会抛出 ConcurrentModificationException。同时我们知道 modCount 在 new 的过程中 “继承”了原列表 modCount，只有在修改该列表（子列表）时才会修改该值（先表现在原列表后作用于子列表）。而在该实例中我们是操作原列表，原列表的 modCount 当然不会反应在子列表的 modCount 上啦，所以才会抛出该异常。 对于子列表视图，它是动态生成的，生成之后就不要操作原列表了，否则必然都导致视图的不稳定而抛出异常。最好的办法就是将原列表设置为只读状态，要操作就操作子列表： //通过subList生成一个与list1一样的列表 list3 List&lt;Integer&gt; list3 = list1.subList(0, list1.size()); //对list1设置为只读状态 list1 = Collections.unmodifiableList(list1); 生成子列表后，不要试图去操作原列表，否则会造成子列表的不稳定而产生异常 三、推荐使用 subList 处理局部列表在开发过程中我们一定会遇到这样一个问题：获取一堆数据后，需要删除某段数据。例如，有一个列表存在 1000 条记录，我们需要删除 100-200 位置处的数据，可能我们会这样处理： for(int i = 0 ; i &lt; list1.size() ; i++){ if(i &gt;= 100 &amp;&amp; i &lt;= 200){ list1.remove(i); /* * 当然这段代码存在问题，list remove之后后面的元素会填充上来， * 所以需要对i进行简单的处理，当然这个不是这里讨论的 问题。 */ } } 这个应该是我们大部分人的处理方式吧，其实还有更好的方法，利用 subList。在前面已经讲过，子列表的操作都会反映在原列表上。所以下面一行代码全部搞定： list1.subList(100, 200).clear(); 简单而不失华丽！！！！！ 原文：http://wiki.jikexueyuan.com/project/java-enhancement/java-thirtyseven.html","categories":[{"name":"Java","slug":"Java","permalink":"https://ldongxu.github.io/categories/Java/"}],"tags":[{"name":"Java集合","slug":"Java集合","permalink":"https://ldongxu.github.io/tags/Java集合/"}]},{"title":"Java 集合细节（二）：asList 的缺陷","slug":"Java-集合细节（二）：asList-的缺陷","date":"2017-06-02T10:22:00.000Z","updated":"2018-07-06T12:33:08.040Z","comments":true,"path":"2017/06/02/Java-集合细节（二）：asList-的缺陷/","link":"","permalink":"https://ldongxu.github.io/2017/06/02/Java-集合细节（二）：asList-的缺陷/","excerpt":"在实际开发过程中我们经常使用 asList 讲数组转换为 List，这个方法使用起来非常方便，但是 asList 方法存在几个缺陷：","text":"在实际开发过程中我们经常使用 asList 讲数组转换为 List，这个方法使用起来非常方便，但是 asList 方法存在几个缺陷： 一、避免使用基本数据类型数组转换为列表使用 8 个基本类型数组转换为列表时会存在一个比较有味的缺陷。先看如下程序：12345public static void main(String[] args) &#123; int[] ints = &#123;1,2,3,4,5&#125;; List list = Arrays.asList(ints); System.out.println(\"list'size：\" + list.size());&#125; outPut： list&apos;size：1 程序的运行结果并没有像我们预期的那样是 5 而是逆天的 1，这是什么情况？先看源码：123public static &lt;T&gt; List&lt;T&gt; asList(T... a) &#123; return new ArrayList&lt;&gt;(a);&#125; asList 接受的参数是一个泛型的变长参数，我们知道基本数据类型是无法泛型化的，也就是说 8 个基本类型是无法作为 asList 的参数的， 要想作为泛型参数就必须使用其所对应的包装类型。但是这个这个实例中为什么没有出错呢？因为该实例是将 int 类型的数组当做其参数，而在 Java 中数组是一个对象，它是可以泛型化的。所以该例子是不会产生错误的。既然例子是将整个 int 类型的数组当做泛型参数，那么经过 asList 转换就只有一个 int 的列表了。如下：123456public static void main(String[] args) &#123; int[] ints = &#123;1,2,3,4,5&#125;; List list = Arrays.asList(ints); System.out.println(&quot;list 的类型:&quot; + list.get(0).getClass()); System.out.println(&quot;list.get(0) == ints：&quot; + list.get(0).equals(ints));&#125; outPut: list 的类型:class [I list.get(0) == ints：true 从这个运行结果我们可以充分证明 list 里面的元素就是 int 数组。弄清楚这点了，那么修改方法也就一目了然了：将 int 改变为 Integer。1234567public static void main(String[] args) &#123; Integer[] ints = &#123;1,2,3,4,5&#125;; List list = Arrays.asList(ints); System.out.println(&quot;list&apos;size：&quot; + list.size()); System.out.println(&quot;list.get(0) 的类型:&quot; + list.get(0).getClass()); System.out.println(&quot;list.get(0) == ints[0]：&quot; + list.get(0).equals(ints[0]));&#125; outPut: list&apos;size：5 list.get(0) 的类型:class java.lang.Integer list.get(0) == ints[0]：true 在使用 asList 时不要将基本数据类型当做参数。 二、asList 产生的列表不可操作对于上面的实例我们再做一个小小的修改：12345public static void main(String[] args) &#123; Integer[] ints = &#123;1,2,3,4,5&#125;; List list = Arrays.asList(ints); list.add(6);&#125; 该实例就是讲 ints 通过 asList 转换为 list 类别，然后再通过 add 方法加一个元素，这个实例简单的不能再简单了，但是运行结果呢？打出我们所料： Exception in thread &quot;main&quot; java.lang.UnsupportedOperationException at java.util.AbstractList.add(Unknown Source) at java.util.AbstractList.add(Unknown Source) at com.chenssy.test.arrayList.AsListTest.main(AsListTest.java:10) 运行结果尽然抛出 UnsupportedOperationException 异常，该异常表示 list 不支持 add 方法。这就让我们郁闷了，list 怎么可能不支持 add 方法呢？难道 JDK 脑袋堵塞了？我们再看 asList 的源码：123public static &lt;T&gt; List&lt;T&gt; asList(T... a) &#123; return new ArrayList&lt;&gt;(a);&#125; asList 接受参数后，直接 new 一个 ArrayList，到这里看应该是没有错误的啊？别急，再往下看:123456789101112private static class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements RandomAccess, java.io.Serializable&#123; private static final long serialVersionUID = -2764017481108945198L; private final E[] a; ArrayList(E[] array) &#123; if (array==null) throw new NullPointerException(); a = array; &#125; //.................&#125; 这是 ArrayList 的源码,从这里我们可以看出,此 ArrayList 不是 java.util.ArrayList，他是 Arrays 的内部类。该内部类提供了 size、toArray、get、set、indexOf、contains 方法，而像 add、remove 等改变 list 结果的方法从 AbstractList 父类继承过来，同时这些方法也比较奇葩，它直接抛出 UnsupportedOperationException 异常：12345678910111213141516public boolean add(E e) &#123; add(size(), e); return true;&#125;public E set(int index, E element) &#123; throw new UnsupportedOperationException();&#125;public void add(int index, E element) &#123; throw new UnsupportedOperationException();&#125;public E remove(int index) &#123; throw new UnsupportedOperationException();&#125; 通过这些代码可以看出 asList 返回的列表只不过是一个披着 list 的外衣，它并没有 list 的基本特性（变长）。该 list 是一个长度不可变的列表，传入参数的数组有多长，其返回的列表就只能是多长。所以：不要试图改变 asList 返回的列表，否则你会自食苦果。 原文：http://wiki.jikexueyuan.com/project/java-enhancement/java-thirtysix.html","categories":[{"name":"Java","slug":"Java","permalink":"https://ldongxu.github.io/categories/Java/"}],"tags":[{"name":"Java集合","slug":"Java集合","permalink":"https://ldongxu.github.io/tags/Java集合/"}]},{"title":"Java 集合细节（一）：请为集合指定初始容量","slug":"Java-集合细节（一）：请为集合指定初始容量","date":"2017-06-02T10:12:28.000Z","updated":"2018-07-06T12:33:08.040Z","comments":true,"path":"2017/06/02/Java-集合细节（一）：请为集合指定初始容量/","link":"","permalink":"https://ldongxu.github.io/2017/06/02/Java-集合细节（一）：请为集合指定初始容量/","excerpt":"集合是我们在 Java 编程中使用非常广泛的，它就像大海，海纳百川，像万能容器，盛装万物，而且这个大海，万能容器还可以无限变大（如果条件允许）。当这个海、容器的量变得非常大的时候，它的初始容量就会显得很重要了，因为挖海、扩容是需要消耗大量的人力物力财力的。同样的道理，Collection 的初始容量也显得异常重要。所以：对于已知的情景，请为集合指定初始容量。","text":"集合是我们在 Java 编程中使用非常广泛的，它就像大海，海纳百川，像万能容器，盛装万物，而且这个大海，万能容器还可以无限变大（如果条件允许）。当这个海、容器的量变得非常大的时候，它的初始容量就会显得很重要了，因为挖海、扩容是需要消耗大量的人力物力财力的。同样的道理，Collection 的初始容量也显得异常重要。所以：对于已知的情景，请为集合指定初始容量。1234567891011121314151617181920public static void main(String[] args) &#123; StudentVO student = null; long begin1 = System.currentTimeMillis(); List&lt;StudentVO&gt; list1 = new ArrayList&lt;&gt;(); for(int i = 0 ; i &lt; 1000000; i++)&#123; student = new StudentVO(i,\"chenssy_\"+i,i); list1.add(student); &#125; long end1 = System.currentTimeMillis(); System.out.println(\"list1 time：\" + (end1 - begin1)); long begin2 = System.currentTimeMillis(); List&lt;StudentVO&gt; list2 = new ArrayList&lt;&gt;(1000000); for(int i = 0 ; i &lt; 1000000; i++)&#123; student = new StudentVO(i,\"chenssy_\"+i,i); list2.add(student); &#125; long end2 = System.currentTimeMillis(); System.out.println(\"list2 time：\" + (end2 - begin2));&#125; 上面代码两个 list 都是插入 1000000 条数据，只不过 list1 没有没有申请初始化容量，而 list2 初始化容量 1000000。那运行结果如下： list1 time：1638 list2 time：921 从上面的运行结果我们可以看出 list2 的速度是 list1 的两倍左右。在前面 LZ 就提过，ArrayList 的扩容机制是比较消耗资源的。我们先看 ArrayList 的 add 方法：1234567891011121314151617181920public boolean add(E e) &#123; ensureCapacity(size + 1); elementData[size++] = e; return true; &#125; public void ensureCapacity(int minCapacity) &#123; modCount++; //修改计数器 int oldCapacity = elementData.length; //当前需要的长度超过了数组长度，进行扩容处理 if (minCapacity &gt; oldCapacity) &#123; Object oldData[] = elementData; //新的容量 = 旧容量 * 1.5 + 1 int newCapacity = (oldCapacity * 3)/2 + 1; if (newCapacity &lt; minCapacity) newCapacity = minCapacity; //数组拷贝，生成新的数组 elementData = Arrays.copyOf(elementData, newCapacity); &#125; &#125; ArrayList 每次新增一个元素，就会检测 ArrayList 的当前容量是否已经到达临界点，如果到达临界点则会扩容 1.5 倍。然而 ArrayList 的扩容以及数组的拷贝生成新的数组是相当耗资源的。所以若我们事先已知集合的使用场景，知道集合的大概范围，我们最好是指定初始化容量，这样对资源的利用会更加好，尤其是大数据量的前提下，效率的提升和资源的利用会显得更加具有优势。 原文：http://wiki.jikexueyuan.com/project/java-enhancement/java-thirtyfive.html","categories":[{"name":"Java","slug":"Java","permalink":"https://ldongxu.github.io/categories/Java/"}],"tags":[{"name":"Java集合","slug":"Java集合","permalink":"https://ldongxu.github.io/tags/Java集合/"}]},{"title":"Java位运算","slug":"Java位运算","date":"2017-06-01T10:38:15.000Z","updated":"2018-07-06T12:33:08.041Z","comments":true,"path":"2017/06/01/Java位运算/","link":"","permalink":"https://ldongxu.github.io/2017/06/01/Java位运算/","excerpt":"Java提供的位运算符有：左移( &lt;&lt; )、右移( &gt;&gt; ) 、无符号右移( &gt;&gt;&gt; ) 、位与( &amp; ) 、位或( | )、位非( ~ )、位异或( ^ )，除了位非( ~ )是一元操作符外，其它的都是二元操作符。","text":"Java提供的位运算符有：左移( &lt;&lt; )、右移( &gt;&gt; ) 、无符号右移( &gt;&gt;&gt; ) 、位与( &amp; ) 、位或( | )、位非( ~ )、位异或( ^ )，除了位非( ~ )是一元操作符外，其它的都是二元操作符。 一、左移( &lt;&lt; )将5左移2位：1234567package com.xcy; public class Test &#123; public static void main(String[] args) &#123; System.out.println(5&lt;&lt;2);//运行结果是20 &#125; &#125; 运行结果是20，但是程序是怎样执行的呢？首先会将5转为2进制表示形式(java中，整数默认就是int类型,也就是32位): 0000 0000 0000 0000 0000 0000 0000 0101 然后左移2位后，低位补0： 0000 0000 0000 0000 0000 0000 0001 0100 换算成10进制为20 二、右移( &gt;&gt; )右移同理，只是方向不一样罢了1System.out.println(5&gt;&gt;2);//运行结果是1 还是先将5转为2进制表示形式： 0000 0000 0000 0000 0000 0000 0000 0101 然后右移2位，高位补0： 0000 0000 0000 0000 0000 0000 0000 0001## 三、无符号右移( &gt;&gt;&gt; )我们知道在Java中int类型占32位，可以表示一个正数，也可以表示一个负数。正数换算成二进制后的最高位为0，负数的二进制最高位为1。例如 -5换算成二进制后为：1111 1111 1111 1111 1111 1111 1111 1011 (二进制最高位是用来表示正负之分的)我们分别对5进行右移3位、 -5进行右移3位和无符号右移3位：123456789package com.xcy; public class Test &#123; public static void main(String[] args) &#123; System.out.println(5&gt;&gt;3);//结果是0 System.out.println(-5&gt;&gt;3);//结果是-1 System.out.println(-5&gt;&gt;&gt;3);//结果是536870911 &#125; &#125;我们来看看它的移位过程(可以通过其结果换算成二进制进行对比)：0000 0000 0000 0000 0000 0000 0000 0101 5换算成二进制0000 0000 0000 0000 0000 0000 0000 0000 5右移3位后结果为0 // (最高位用0进行补位)1111 1111 1111 1111 1111 1111 1111 1011 -5换算成二进制1111 1111 1111 1111 1111 1111 1111 1111 -5右移3位后结果为-1 // (最高位用1进行补位)-5无符号右移3位后的结果 536870911 换算成二进制：0001 1111 1111 1111 1111 1111 1111 1111 // (最高位用0进行补位)通过其结果转换成二进制后，我们可以发现，正数右移，高位用0补，负数右移，高位用1补，当负数使用无符号右移时，用0进行部位(自然而然的，就由负数变成了正数了)注意：在这里说的是右移，高位补位的情况。正数或者负数左移，低位都是用0补。## 四、位与( &amp; )1234567package com.xcy; public class Test &#123; public static void main(String[] args) &#123; System.out.println(5 &amp; 3);//结果为1 &#125; &#125;还是老套路，将2个操作数和结果都转换为二进制进行比较：5转换为二进制：0000 0000 0000 0000 0000 0000 0000 01013转换为二进制：0000 0000 0000 0000 0000 0000 0000 00111转换为二进制：0000 0000 0000 0000 0000 0000 0000 0001位与：第一个操作数的的第n位于第二个操作数的第n位如果都是1，那么结果的第n为也为1，否则为0。 五、位或( | )1234567package com.xcy; public class Test &#123; public static void main(String[] args) &#123; System.out.println(5 | 3);//结果为7 &#125; &#125; 5转换为二进制：0000 0000 0000 0000 0000 0000 0000 0101 3转换为二进制：0000 0000 0000 0000 0000 0000 0000 0011 7转换为二进制：0000 0000 0000 0000 0000 0000 0000 0111 位或操作：第一个操作数的的第n位于第二个操作数的第n位 只要有一个是1，那么结果的第n为也为1，否则为0。 六、位异或( ^ )1234567package com.xcy; public class Test &#123; public static void main(String[] args) &#123; System.out.println(5 ^ 3);//结果为6 &#125; &#125; 5转换为二进制：0000 0000 0000 0000 0000 0000 0000 0101 3转换为二进制：0000 0000 0000 0000 0000 0000 0000 0011 6转换为二进制：0000 0000 0000 0000 0000 0000 0000 0110 位异或：第一个操作数的的第n位于第二个操作数的第n位 相反，那么结果的第n为也为1，否则为0。 七、位非( ~ )位非是一元操作符1234567package com.xcy; public class Test &#123; public static void main(String[] args) &#123; System.out.println(~5);//结果为-6 &#125; &#125; 5转换为二进制：0000 0000 0000 0000 0000 0000 0000 0101 -6转换为二进制：1111 1111 1111 1111 1111 1111 1111 1010 位非：操作数的第n位为1，那么结果的第n位为0，反之。 由位运算操作符衍生而来的有： &amp;= 按位与赋值 |= 按位或赋值 ^= 按位非赋值 &gt;&gt;= 右移赋值 &gt;&gt;&gt;= 无符号右移赋值 &lt;&lt;= 赋值左移 和 +=一个概念而已。 举个例子：123456789package com.xcy; public class Test &#123; public static void main(String[] args) &#123; int a = 5 a &amp;= 3; System.out.println(a);//结果是1 &#125; &#125; 原文参考：http://blog.csdn.net/xiaochunyong/article/details/7748713","categories":[{"name":"Java","slug":"Java","permalink":"https://ldongxu.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://ldongxu.github.io/tags/Java/"}]},{"title":"Java中类与对象的比较及hashCode和equals方法详解","slug":"Java中类与对象的比较及hashCode和equals方法详解","date":"2017-05-26T07:03:49.000Z","updated":"2018-07-06T12:33:08.041Z","comments":true,"path":"2017/05/26/Java中类与对象的比较及hashCode和equals方法详解/","link":"","permalink":"https://ldongxu.github.io/2017/05/26/Java中类与对象的比较及hashCode和equals方法详解/","excerpt":"重新认识理解Java类、对象之间的对比，和equals和hashCode方法重要性。","text":"重新认识理解Java类、对象之间的对比，和equals和hashCode方法重要性。 类与类的比较类与类的比较，通常有两种方式： 1、 直接用 == 比较class：在Java中，类是静态的，唯一的，共享的单例，所以这里用 == 在恰当不过了，使用 == 更能说明实现关系。 123456789Integer obj1 = 1;Integer obj2 = 1;if(Integer.class == Integer.class) &#123; // true&#125;if(obj1.getClass() == obj2.getClass()) &#123; // true&#125; 2、 比较 class.getName()。123456789Integer obj1 = 1;Integer obj2 = 1;if(Integer.class.getName() == Integer.class.getName()) &#123; // true&#125;if(obj1.getClass().getName() == obj2.getClass().getName()) &#123; // true&#125; 类与对象的比较判读啊一个对象和一个类是不是具有实现关系，通常有两种方式： 1、obj instanceof Class ： 12345678910// 注意：obj 不能是原始类型，例如 int, long// obj 只能是引用类型，例如 Integer, LongInteger obj = 1;if(obj instanceof Integer) &#123; // true&#125;if(obj instanceof Object) &#123; // true&#125; 实现方式：先判断 obj 是不是 null，随后判断 obj.getClass() 与 Integer.class 是否相等。因此 instanceof 相等于：if(obj != null &amp;&amp; obj.getClass() == Integer.class) instanceof 用于检测类与对象的 直接实现关系，检测方式是 对象-&gt;类。 2、 Class&lt;?&gt;.isInstance(obj) 123456789// 注意：obj 可以是引用类型，也可以是原始类型，例如 int, longInteger obj = 1;if(Integer.class.isInstance(obj)) &#123; // true&#125;if(Object.class.isInstance(obj)) &#123; // true&#125; Class&lt;?&gt;.isInstance(obj) 用于检测 非直接实现关系，检测方式是 类-&gt;对象。 isInstance是用C语言 native 代码实现的。当一个类继承了某个接口，类，或者而是抽象类。那么，isInstance 旨在查找出这个对象到底实现了哪些类。1234567891011121314interface I &#123;&#125;class A implements I &#123;&#125;class B extends A &#123;&#125;B b = new B();I.class.isInstance(b); //查询b是不是实现了接口I trueA.class.isInstance(b);//查询b是不实现了A类 trueB.class.isInstance(b);//查询b是不实现了B类 true 通常来说 ,对于一个对象和一个类来说，(obj instanceOf ObjClass) 关系如果为真，那么Class&lt;?.isInstance(obj)关系也为真。但反过来就不一样了。Class&lt;?&gt;.isInstance(obj)更加适合 泛类型 的检测（如代理，接口，抽象类等规则）而 instanceOf符合直接类型的检测。 对象与对象的比较一、基本类型比较 Java中，基本类型比较用“==”，只要两个基本类型值相等即返回ture，否则返回false。 二、引用类型比较 引用类型比较比较变态，可以用“==”，也可以用“equals()”来比较，equals()方法来自于Object类，每个自定义的类都可以重写这个方法。Object类中的equals()方法仅仅通过“==”来比较两个对象是否相等。 在用“==”比较引用类型时，仅当两个应用变量的对象指向同一个对象时，才返回ture。言外之意就是要求两个变量所指内存地址相等的时候，才能返回true，每个对象都有自己的一块内存，因此必须指向同一个对象才返回ture。 我们看一个例子，让我们创建一个简单的类Employee：1234567891011121314151617181920212223242526272829303132public class Employee&#123; private Integer id; private String firstname; private String lastName; private String department; public Integer getId() &#123; return id; &#125; public void setId(Integer id) &#123; this.id = id; &#125; public String getFirstname() &#123; return firstname; &#125; public void setFirstname(String firstname) &#123; this.firstname = firstname; &#125; public String getLastName() &#123; return lastName; &#125; public void setLastName(String lastName) &#123; this.lastName = lastName; &#125; public String getDepartment() &#123; return department; &#125; public void setDepartment(String department) &#123; this.department = department; &#125;&#125; 1234567891011public class EqualsTest &#123; public static void main(String[] args) &#123; Employee e1 = new Employee(); Employee e2 = new Employee(); e1.setId(100); e2.setId(100); System.out.println(e1.equals(e2)); //Prints false in console &#125;&#125; 毫无疑问，上面的程序将输出false。接下来我们重写一下equals()方法：12345678910111213141516public boolean equals(Object o) &#123; if(o == null) &#123; return false; &#125; if (o == this) &#123; return true; &#125; if (getClass() != o.getClass()) &#123; return false; &#125; Employee e = (Employee) o; return (this.getId() == e.getId());&#125; 在重写equals方法后，EauqlsTest将会输出true。 但是现在有一种情况，请看下面示例：123456789101112131415161718192021import java.util.HashSet;import java.util.Set;public class EqualsTest&#123; public static void main(String[] args) &#123; Employee e1 = new Employee(); Employee e2 = new Employee(); e1.setId(100); e2.setId(100); System.out.println(e1.equals(e2)); //Prints &apos;true&apos; Set&lt;Employee&gt; employees = new HashSet&lt;Employee&gt;(); employees.add(e1); System.out.println(employees.contains(e2)); // Print ‘false’ &#125;&#125; 如果两个employee对象equals返回true，Set中应该只存储一个对象employees.contains(e2)应该返回true才对，问题在哪里呢？我们忘掉了第二个重要的方法hashCode()。 就像JDK的Javadoc中所说的一样，如果重写equals()方法必须要重写hashCode()方法。 需要注意的 尽量保证使用对象的同一个属性来生成hashCode()和equals()两个方法。在我们的案例中,我们使用员工id。 eqauls方法必须保证一致（如果对象没有被修改，equals应该返回相同的值） 任何时候只要a.equals(b),那么a.hashCode()必须和b.hashCode()相等。 两者必须同时重写。 当使用ORM的时候特别要注意的 如果你使用ORM处理一些对象的话，你要确保在hashCode()和equals()对象中使用getter和setter而不是直接引用成员变量。因为在ORM中有的时候成员变量会被延时加载，这些变量只有当getter方法被调用的时候才真正可用。 例如在我们的例子中，如果我们使用e1.id == e2.id则可能会出现这个问题，但是我们使用e1.getId() == e2.getId()就不会出现这个问题。 equals()和hashCode()方法java.lang.Object类中有两个非常重要的方法：12public boolean equals(Object obj)public int hashCode() Object类是类继承结构的基础，所以是每一个类的父类。所有的对象，包括数组，都实现了在Object类中定义的方法。 一、equals()方法详解equals()方法是用来判断其他的对象是否和该对象相等. equals()方法在object类中定义如下：123public boolean equals(Object obj) &#123; return (this == obj); &#125; 很明显是对两个对象的地址值进行的比较（即比较引用是否相同）。但是我们知道，String 、Math、Integer、Double等这些封装类在使用equals()方法时，已经覆盖了object类的equals()方法。 比如在String类中如下：123456789101112131415161718192021public boolean equals(Object anObject) &#123; if (this == anObject) &#123; return true; &#125; if (anObject instanceof String) &#123; String anotherString = (String)anObject; int n = count; if (n == anotherString.count) &#123; char v1[] = value; char v2[] = anotherString.value; int i = offset; int j = anotherString.offset; while (n– != 0) &#123; if (v1[i++] != v2[j++]) return false; &#125; return true; &#125; &#125; return false; &#125; 很明显，这是进行的内容比较，而已经不再是地址的比较。依次类推Math、Integer、Double等这些类都是重写了equals()方法的，从而进行的是内容的比较。当然，基本类型是进行值的比较。 equals方法的性质有： 自反性（reflexive）。对于任意不为null的引用值x，x.equals(x)一定是true。 对称性（symmetric）。对于任意不为null的引用值x和y，当且仅当x.equals(y)是true时，y.equals(x)也是true。 传递性（transitive）。对于任意不为null的引用值x、y和z，如果x.equals(y)是true，同时y.equals(z)是true，那么x.equals(z)一定是true。 一致性（consistent）。对于任意不为null的引用值x和y，如果用于equals比较的对象信息没有被修改的话，多次调用时x.equals(y)要么一致地返回true要么一致地返回false。 对于任意不为null的引用值x，x.equals(null)返回false。 对于Object类来说，equals()方法在对象上实现的是差别可能性最大的等价关系，即，对于任意非null的引用值x和y，当且仅当x和y引用的是同一个对象，该方法才会返回true。 需要注意的是当equals()方法被override时，hashCode()也要被override。按照一般hashCode()方法的实现来说，相等的对象，它们的hash code一定相等。 二、hashcode()方法详解hashCode()方法给对象返回一个hash code值。这个方法被用于hash tables，例如HashMap。 它的性质是： 在一个Java应用的执行期间，如果一个对象提供给equals做比较的信息没有被修改的话，该对象多次调用hashCode()方法，该方法必须始终如一返回同一个integer。 如果两个对象根据equals(Object)方法是相等的，那么调用二者各自的hashCode()方法必须产生同一个integer结果。 并不要求根据equals(java.lang.Object)方法不相等的两个对象，调用二者各自的hashCode()方法必须产生不同的integer结果。然而，程序员应该意识到对于不同的对象产生不同的integer结果，有可能会提高hash table的性能。 大量的实践表明，由Object类定义的hashCode()方法对于不同的对象返回不同的integer。 在object类中，hashCode定义如下：1public native int hashCode(); 说明是一个本地方法，它的实现是根据本地机器相关的。当然我们可以在自己写的类中覆盖hashcode()方法，比如String、Integer、Double等这些类都是覆盖了hashcode()方法的。例如在String类中定义的hashcode()方法如下：1234567891011121314public int hashCode() &#123; int h = hash; if (h == 0) &#123; int off = offset; char val[] = value; int len = count; for (int i = 0; i &lt; len; i++) &#123; h = 31 * h + val[off++]; &#125; hash = h; &#125; return h; &#125; 想要弄明白hashCode的作用，必须要先知道Java中的集合。 总的来说，Java中的集合（Collection）有两类，一类是List，再有一类是Set。前者集合内的元素是有序的，元素可以重复；后者元素无序，但元素不可重复。这里就引出一个问题：要想保证元素不重复，可两个元素是否重复应该依据什么来判断呢？ 这就是Object.equals方法了。但是，如果每增加一个元素就检查一次，那么当元素很多时，后添加到集合中的元素比较的次数就非常多了。也就是说，如果集合中现在已经有1000个元素，那么第1001个元素加入集合时，它就要调用1000次equals方法。这显然会大大降低效率。 于是，Java采用了哈希表的原理。哈希（Hash）实际上是个人名，由于他提出一哈希算法的概念，所以就以他的名字命名了。哈希算法也称为散列算法，是将数据依特定算法直接指定到一个地址上，初学者可以简单理解，hashCode方法实际上返回的就是对象存储的物理地址（实际可能并不是）。 这样一来，当集合要添加新的元素时，先调用这个元素的hashCode方法，就一下子能定位到它应该放置的物理位置上。如果这个位置上没有元素，它就可以直接存储在这个位置上，不用再进行任何比较了；如果这个位置上已经有元素了，就调用它的equals方法与新元素进行比较，相同的话就不存了，不相同就散列其它的地址。所以这里存在一个冲突解决的问题。这样一来实际调用equals方法的次数就大大降低了，几乎只需要一两次。 简而言之，在集合查找时，hashcode能大大降低对象比较次数，提高查找效率！ Java对象的eqauls方法和hashCode方法是这样规定的： 1、相等（相同）的对象必须具有相等的哈希码（或者散列码）。 2、如果两个对象的hashCode相同，它们并不一定相同。 以下是Object对象API关于equal方法和hashCode方法的说明(是对之前2点的官方详细说明)： If two objects are equal according to the equals(Object) method, then calling the hashCode method on each of the two objects must produce the same integer result. It is not required that if two objects are unequal according to the equals(java.lang.Object) method, then calling the hashCode method on each of the two objects must produce distinct integer results. However, the programmer should be aware that producing distinct integer results for unequal objects may improve the performance of hash tables. 如不按要求去做了，会发现相同的对象可以出现在Set集合中，同时，增加新元素的效率会大大下降。 在object类中，hashcode()方法是本地方法，返回的是对象的地址值，而object类中的equals()方法比较的也是两个对象的地址值，如果equals()相等，说明两个对象地址值也相等，当然hashcode()也就相等了；在String类中，equals()返回的是两个对象内容的比较，当两个对象内容相等时，Hashcode()方法根据String类的重写代码的分析，也可知道hashcode()返回结果也会相等。以此类推，可以知道Integer、Double等封装类中经过重写的equals()和hashcode()方法也同样适合于这个原则。当然没有经过重写的类，在继承了object类的equals()和hashcode()方法后，也会遵守这个原则。 三、示例说明下面以HashSet为例进行分析，我们都知道：在hashSet中不允许出现重复对象，元素的位置也是不确定的。在hashset中又是怎样判定元素是否重复的呢？ 在java的集合中，判断两个对象是否相等的规则是： 1.判断两个对象的hashCode是否相等 如果不相等，认为两个对象也不相等，完毕； 如果相等，转入2。 （这一点只是为了提高存储效率而要求的，其实理论上没有也可以，但如果没有，实际使用时效率会大大降低，所以我们这里将其做为必需的。） 2.判断两个对象用equals运算是否相等 如果不相等，认为两个对象也不相等; 如果相等，认为两个对象相等。（equals()是判断两个对象是否相等的关键） 例：12345678910111213141516171819202122232425262728293031323334package com.bijian.study;import java.util.HashSet;import java.util.Iterator;public class HashSetTest &#123; public static void main(String[] args) &#123; HashSet hs = new HashSet(); hs.add(new Student(1, &quot;zhangsan&quot;)); hs.add(new Student(2, &quot;lisi&quot;)); hs.add(new Student(3, &quot;wangwu&quot;)); hs.add(new Student(1, &quot;zhangsan&quot;)); Iterator it = hs.iterator(); while (it.hasNext()) &#123; System.out.println(it.next()); &#125; &#125;&#125;class Student &#123; int num; String name; Student(int num, String name) &#123; this.num = num; this.name = name; &#125; public String toString() &#123; return num + &quot;:&quot; + name; &#125;&#125; 运行结果： 1:zhangsan 3:wangwu 2:lisi 1:zhangsan 为什么hashSet添加了相等的元素呢，这是不是和hashset的原则违背了呢？回答是：没有。因为在根据hashcode()对两次建立的new Student(1,“zhangsan”)对象进行比较时，生成的是不同的哈希码值，所以hashset把他当作不同的对象对待了，当然此时的equals()方法返回的值也不等。 怎么解决这个问题呢？答案是：在Student类中重新hashcode()和equals()方法。 重写equals()和hashcode()小结： 1.重点是equals，重写hashCode只是技术要求（为了提高效率） 2.为什么要重写equals呢？因为在java的集合框架中，是通过equals来判断两个对象是否相等的 3.在hibernate中，经常使用set集合来保存相关对象，而set集合是不允许重复的。在向HashSet集合中添加元素时，其实只要重写equals()这一条也可以。但当hashSet中元素比较多时，或者是重写的equals()方法比较复杂时，我们只用equals()方法进行比较判断，效率也会非常低，所以引入了hashCode()这个方法，只是为了提高效率，且这是非常有必要的。 比如可以这样写：123public int hashCode()&#123; return 1; //等价于hashcode无效 &#125; 这样做的效果就是在比较哈希码的时候不能进行判断，因为每个对象返回的哈希码都是1，每次都必须要经过比较equals()方法后才能进行判断是否重复，但这会引起效率的大大降低。","categories":[{"name":"Java","slug":"Java","permalink":"https://ldongxu.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://ldongxu.github.io/tags/Java/"}]},{"title":"Java初始化","slug":"Java初始化","date":"2017-05-24T02:46:51.000Z","updated":"2018-07-06T12:33:08.041Z","comments":true,"path":"2017/05/24/Java初始化/","link":"","permalink":"https://ldongxu.github.io/2017/05/24/Java初始化/","excerpt":"理解Java初始化过程及顺序能更清楚的知道代码的执行顺序，特别是在需要特定的执行顺序的时候就显的更为关键。","text":"理解Java初始化过程及顺序能更清楚的知道代码的执行顺序，特别是在需要特定的执行顺序的时候就显的更为关键。Java的初始化可以分为两个部分： 类的初始化 对象的创建 类的初始化一、什么是类的初始化 一个类(class)要被使用必须经过装载，连接，初始化这样的过程。 在装载阶段，类装载器会把编译形成的class文件载入内存，创建类相关的Class对象，这个Class对象封装了我们要使用的类的类型信息。 连接阶段又可以分为三个子步骤：验证、准备和解析。 验证就是要确保java类型数据格式的正确性，并适于JVM使用。 准备阶段，JVM为静态变量分配内存空间，并设置默认值，注意，这里是设置默认值，比如说int型的变量会被赋予默认值0。在这个阶段，JVM可能还会为一些数据结构分配内存，目的是提高运行程序的性能，比如说方法表。 解析过程就是在类型的常量池中寻找类、接口、字段和方法的符号引用，把这些符号引用替换成直接引用。这个阶段可以被推迟到初始化之后，当程序运行的过程中真正使用某个符号引用的时候 再去解析它。 初始化：类的初始化，是指初始化static静态变量和执行static静态代码块。初始化接口，是指初始化定义在该接口中的filed。 二、类的初始化条件类会在首次被“主动使用”时执行初始化，以下情况第一次发生之前类会被初始化： 创建类的实例； 调用类的静态方法； 调用类的静态变量，并且该变量不是一个常变量； 为类的静态字段赋值； 在顶层类中执行assert语句；（？） 调用类Class及包java.lang.reflect中的某些反射方法； JLS严格的说明：在任何其他的情况下，都不会对类或接口进行初始化。 三、类的初始化规则 类初始化时，该类的父类将首先被初始化，此过程一直递归到 java.lang.Object为止。但是父类实现的接口并不会被初始化。 接口初始化时，只会初始化该接口本身，并不会初始化它的父接口。 如果类的初始化是由于访问静态域而触发，那么只有真正定义该静态域的类才被初始化，而不会触发超类的初始化或者子类的初始化即使静态域被子类或子接口或者它的实现类所引用。 如果一个静态变量是编译时常量，则对它的引用不会引起定义它的类的初始化。 初始化类是指初始化static静态变量和执行static静态代码块，所以只会进行一次。初始化接口也只会进行一次。 对象创建过程中的Java初始化一. 对象的创建过程 假设有个名为Dog的类： 当首次创建类型为Dog的对象时，或者Dog类的静态方法/静态域首次被访问时，java解释器必须查找类路径，以定位Dog.class文件。 然后载入Dog.class（这将创建一个Class对象），有关静态初始化的所有动作都会执行。因此，静态初始化只在class对象首次加载的时候进行一次。 当用new Dog()创建对象的时候，首先将在堆上为Dog对象分配足够的存储空间。 这块存储空间会被清零，这就自动地将Dog对象中的所有基本类型数据都设置成了默认值（对数字来说就是0，对布尔型与字符型也相同），而引用则被设置成了null。 执行所有出现于字段定义处的初始化动作。 执行构造器。—《Thinking in java》 二. 对象创建过程中初始化顺序父静态成员&gt;子静态成员&gt;父普通成员初始化&gt;父构造&gt;子普通成员初始化&gt;子构造.( 静态初始化块以静态变量对待) 三. 对象创建过程的说明 静态域的初始化是在类的初始化期间，非静态域的初始化时在类的实例创建期间。这意味这静态域初始化在非静态域之前。 非静态域通过构造器初始化，子类在做任何初始化之前构造器会隐含地调用父类的构造器，这保证了父类非静态实例变量初始化早于子类。 调用Class的类成员变量(也就是静态变量)时，构造函数和成员变量不会执行。 在类的内部，变量定义的先后顺序决定了初始化的顺序;即使变量定义散布于方法定义之间，它们仍会在任何方法（包括构造器）被调用之前得到初始化。 多态情况下的初始化与继承情况下的初始化是一样的，因为都是创建的子类的实例。 程序的执行过程，即Java虚拟机执行Test类的静态方法main，这也会引起Test 类的初始化。（理解面向对象而非面向过程）","categories":[{"name":"Java","slug":"Java","permalink":"https://ldongxu.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://ldongxu.github.io/tags/Java/"},{"name":"Java初始化","slug":"Java初始化","permalink":"https://ldongxu.github.io/tags/Java初始化/"}]},{"title":"用mongodb的Java驱动做查询－－解决$regex和$nin并列查询问题","slug":"用mongodb的Java驱动做查询－－解决$regex和$nin并列查询问题","date":"2017-04-25T13:53:24.000Z","updated":"2018-07-06T12:33:08.043Z","comments":true,"path":"2017/04/25/用mongodb的Java驱动做查询－－解决$regex和$nin并列查询问题/","link":"","permalink":"https://ldongxu.github.io/2017/04/25/用mongodb的Java驱动做查询－－解决$regex和$nin并列查询问题/","excerpt":"用mongodb的Java驱动而非Spring-data-mongodb的封装，以db.runCommand方式做查询。","text":"用mongodb的Java驱动而非Spring-data-mongodb的封装，以db.runCommand方式做查询。开发中遇到一个需求是利用mongodb模糊查询查询除已选中的标签外的其它标签，比如：标签库中有‘Java，Javascript，Jade，Core Java，Node.js，Python，JavaEE’，已选中的标签有‘Java，Jade’，现在输入‘ja’需要查出包含‘ja’(不区分大小写)的标签并且排除已选中的‘Java，Jade’。 用Spring-data-mongodb做$regex和$nin模糊查询时的问题1234567891011121314151617181920212223242526package com.ldongxu.dao;import com.ldongxu.domain.Skill;import org.springframework.data.mongodb.core.query.Criteria;import org.springframework.data.mongodb.core.query.Query;import org.springframework.stereotype.Repository;import java.util.List;import java.util.regex.Pattern;@Repositorypublic class SkillDao extends BaseDao &#123; @Autowired protected MongoTemplate mongoTemplate; public List&lt;Skill&gt; findByRegex(String keyWord, List&lt;String&gt; existTags, Integer limit)&#123; Pattern pattern = Pattern.compile(\"^.*\" + keyWord + \".*$\", Pattern.CASE_INSENSITIVE);//js正则忽略大小写 Criteria criteria = Criteria.where(\"skillTag\").regex(pattern); if (existTags != null &amp;&amp; !existTags.isEmpty())&#123; criteria.nin(existTags); &#125; Query query = Query.query(criteria); query.limit(limit); return mongoTemplate.find(query,Skill.class); &#125;&#125; 利用这种方式得出的mongodb查询语句是这样的：12345678910111213db.skill.find(&#123; &quot;skillTag&quot; : &#123; &quot;$regex&quot; : &quot;^.*ja.*$&quot; , &quot;$options&quot; : &quot;i&quot;&#125; , &quot;$nin&quot; : [ &quot;Jade&quot; , &quot;Java&quot;]&#125;)&#123; &quot;skillTag&quot;: &#123; &quot;$regex&quot;: &quot;^.*ja.*$&quot;, &quot;$options&quot;: &quot;i&quot; &#125;, &quot;$nin&quot;: [ &quot;Jade&quot;, &quot;Java&quot; ]&#125; 而且执行是报如下错误：1234Error: error: &#123; &quot;$err&quot; : &quot;Can&apos;t canonicalize query: BadValue unknown top level operator: $nin&quot;, &quot;code&quot; : 17287&#125; 那么问题来了，$regex和$nin不能并列做查询条件么？ mongodb的Java驱动做db.runCommand查询在mongodb官方文档中找到一段话： To include a regular expression in a comma-separated list of query conditions for the field, use the $regex operator. For example:（为了字段在以逗号分隔的查询条件列表中包含正则表达式，可以使用$regex运算符。例如：）123&#123; name: &#123; $regex: /acme.*corp/i, $nin: [ &apos;acmeblahcorp&apos; ] &#125; &#125;&#123; name: &#123; $regex: /acme.*corp/, $options: &apos;i&apos;, $nin: [ &apos;acmeblahcorp&apos; ] &#125; &#125;&#123; name: &#123; $regex: &apos;acme.*corp&apos;, $options: &apos;i&apos;, $nin: [ &apos;acmeblahcorp&apos; ] &#125; &#125; 由此，需求中的mongodb查询语句应该是这样的：1db.skill.find(&#123; &quot;skillTag&quot; : &#123; &quot;$regex&quot; : &quot;^.*ja.*$&quot; , &quot;$options&quot; : &quot;i&quot; , &quot;$nin&quot; : [ &quot;Jade&quot; , &quot;Java&quot;]&#125;&#125;) db.runCommand()的方式一：利用Spring-data-mongodbAPI始终是组合不到这样的查询语句，所以选择用mongodb的Java驱动以db.runCommand()的方式实现，如下：123456789101112131415161718192021222324public List&lt;Skill&gt; findByRegex(String keyWord, List&lt;String&gt; existTags, Integer limit) &#123; String collectionName = mongoTemplate.getCollectionName(Skill.class); DBObject filter = new BasicDBObject(); DBObject condition = new BasicDBObject(); Pattern pattern = Pattern.compile(&quot;^.*&quot; + keyWord + &quot;.*$&quot;, Pattern.CASE_INSENSITIVE); condition.put(&quot;$regex&quot;,pattern); if (existTags != null &amp;&amp; existTags.size() &gt; 0) &#123; condition.put(&quot;$nin&quot;,existTags); &#125; filter.put(&quot;skillTag&quot;,condition); DBCollection dbCollection = mongoTemplate.getCollection(collectionName); Cursor cursor = dbCollection.find(filter).limit(limit); List&lt;Skill&gt; skillList = new ArrayList&lt;&gt;(); while (cursor.hasNext())&#123; DBObject object = cursor.next(); Skill skill = new Skill(); skill.set_id(object.get(&quot;_id&quot;).toString()); skill.setSkillTag(object.get(&quot;skillTag&quot;).toString()); skill.setAddTime((Date) object.get(&quot;addTime&quot;)); skill.setStatus(Byte.valueOf(object.get(&quot;status&quot;).toString())); skillList.add(skill); &#125; return skillList; &#125; db.runCommand()的方式二：也可以按mongodb的find原生定义命令进行查询。mongodb官方文档中对find命令的定义如下： findNew in version 3.2.Executes a query and returns the first batch of results and the cursor id, from which the client can construct a cursor.The find command has the following form:1234567891011121314151617181920212223242526&#123; &quot;find&quot;: &lt;string&gt;, &quot;filter&quot;: &lt;document&gt;, &quot;sort&quot;: &lt;document&gt;, &quot;projection&quot;: &lt;document&gt;, &quot;hint&quot;: &lt;document or string&gt;, &quot;skip&quot;: &lt;int&gt;, &quot;limit&quot;: &lt;int&gt;, &quot;batchSize&quot;: &lt;int&gt;, &quot;singleBatch&quot;: &lt;bool&gt;, &quot;comment&quot;: &lt;string&gt;, &quot;maxScan&quot;: &lt;int&gt;, &quot;maxTimeMS&quot;: &lt;int&gt;, &quot;readConcern&quot;: &lt;document&gt;, &quot;max&quot;: &lt;document&gt;, &quot;min&quot;: &lt;document&gt;, &quot;returnKey&quot;: &lt;bool&gt;, &quot;showRecordId&quot;: &lt;bool&gt;, &quot;snapshot&quot;: &lt;bool&gt;, &quot;tailable&quot;: &lt;bool&gt;, &quot;oplogReplay&quot;: &lt;bool&gt;, &quot;noCursorTimeout&quot;: &lt;bool&gt;, &quot;awaitData&quot;: &lt;bool&gt;, &quot;allowPartialResults&quot;: &lt;bool&gt;, &quot;collation&quot;: &lt;document&gt;&#125; 详细参考：https://docs.mongodb.com/manual/reference/command/find/mongodb的Java驱动db.runCommand()的方式也可以写成：12345678910111213141516171819202122232425262728293031public List&lt;Skill&gt; findByRegex(String keyWord, List&lt;String&gt; existTags, Integer limit) &#123; String collectionName = mongoTemplate.getCollectionName(Skill.class); DBObject command = new BasicDBObject(); command.put(&quot;find&quot;,collectionName); DBObject filter = new BasicDBObject(); DBObject condition = new BasicDBObject(); Pattern pattern = Pattern.compile(&quot;^.*&quot; + keyWord + &quot;.*$&quot;, Pattern.CASE_INSENSITIVE); condition.put(&quot;$regex&quot;,pattern); if (existTags != null &amp;&amp; existTags.size() &gt; 0) &#123; condition.put(&quot;$nin&quot;,existTags); &#125; filter.put(&quot;skillTag&quot;,condition); command.put(&quot;filter&quot;,filter); command.put(&quot;limit&quot;,limit); DBCollection dbCollection = mongoTemplate.getCollection(collectionName); CommandResult commandResult = dbCollection.getDB().command(command); List&lt;Skill&gt; skillList = new ArrayList&lt;&gt;(); DBObject r = (DBObject) commandResult.get(&quot;cursor&quot;); BasicDBList dbObjectList = (BasicDBList) r.get(&quot;firstBatch&quot;); Iterator&lt;Object&gt; iterator = dbObjectList.iterator(); while (iterator.hasNext())&#123; DBObject object = (DBObject) iterator.next(); Skill skill = new Skill(); skill.set_id(object.get(&quot;_id&quot;).toString()); skill.setSkillTag(object.get(&quot;skillTag&quot;).toString()); skill.setAddTime((Date) object.get(&quot;addTime&quot;)); skill.setStatus(Byte.valueOf(object.get(&quot;status&quot;).toString())); skillList.add(skill); &#125; return skillList; &#125; 产生的find command格式：123456789101112131415161718&#123; &quot;find&quot; : &quot;skill&quot; , &quot;filter&quot; : &#123; &quot;skillTag&quot; : &#123; &quot;$regex&quot; : &#123; &quot;$regex&quot; : &quot;^.*ja.*$&quot; , &quot;$options&quot; : &quot;i&quot;&#125; , &quot;$nin&quot; : [ &quot;Jade&quot; , &quot;Java&quot;]&#125;&#125; , &quot;limit&quot; : 6&#125;&#123; &quot;find&quot;: &quot;skill&quot;, &quot;filter&quot;: &#123; &quot;skillTag&quot;: &#123; &quot;$regex&quot;: &#123; &quot;$regex&quot;: &quot;^.*ja.*$&quot;, &quot;$options&quot;: &quot;i&quot; &#125;, &quot;$nin&quot;: [ &quot;Jade&quot;, &quot;Java&quot; ] &#125; &#125;, &quot;limit&quot;: 6&#125;","categories":[{"name":"Mongodb","slug":"Mongodb","permalink":"https://ldongxu.github.io/categories/Mongodb/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://ldongxu.github.io/tags/Java/"},{"name":"Mongodb","slug":"Mongodb","permalink":"https://ldongxu.github.io/tags/Mongodb/"}]},{"title":"Linux同步工具：rsync","slug":"Linux同步工具：rsync","date":"2017-04-13T08:11:40.000Z","updated":"2018-07-06T12:33:08.042Z","comments":true,"path":"2017/04/13/Linux同步工具：rsync/","link":"","permalink":"https://ldongxu.github.io/2017/04/13/Linux同步工具：rsync/","excerpt":"rsync是一款Linux上的文件远程同步工具。rsync使用所谓的“rsync算法”来使本地和远程两个主机之间的文件达到同步，这个算法只传送两个文件的不同部分，而不是每次都整份传送，因此速度相当快。 rsync是一个功能非常强大的工具，其命令也有很多功能特色选项，我们下面就对它的选项一一进行分析说明。","text":"rsync是一款Linux上的文件远程同步工具。rsync使用所谓的“rsync算法”来使本地和远程两个主机之间的文件达到同步，这个算法只传送两个文件的不同部分，而不是每次都整份传送，因此速度相当快。 rsync是一个功能非常强大的工具，其命令也有很多功能特色选项，我们下面就对它的选项一一进行分析说明。 安装一般的Linux系统都自带了这个工具，如果没有的话，可以用下面的命令安装123$ wget https://download.samba.org/pub/rsync/src/rsync-3.1.2.tar.gz$ tar -xvzf rsync-3.1.2.tar.gz &amp;&amp; cd rsync-3.1.2$ ./configure &amp;&amp; make &amp;&amp; sudo make install 服务器端假设我们有一个目录/home/ldongxu/backup/mysql需要同步，创建配置文件12$ sudo touch /etc/rsyncd.conf$ sudo vi /etc/rsyncd.conf 加入下面的内容12345678910111213141516171819202122232425262728293031# SYNC守护进程的用户uid = root# 运行RSYNC守护进程的组gid = root# 不使用chrootuse chroot = no# 最大连接数是4max connections = 4# pid文件存放位置pid file = /var/run/rsyncd.pid# 锁文件存放位置lock file = /var/run/rsync.lock# 日志文件存放位置log file = /var/log/rsyncd.log[mysql]# 要同步的目录path = /home/ldongxu/backup/mysql# 忽略无关的IO错误ignore errors# 只读，不能上传read only = true# 禁止查看文件列表list = false# 允许访问服务的ip# hosts allow = 192.168.1.200# 禁止访问服务的ip# hosts deny = 0.0.0.0/32# 认证的用户名，系统必须存在的用户，但是密码需要在secrets file 配置，不是系统的密码。auth users = ldongxu# 认证用户密码文件，配置auth users的密码secrets file = /etc/backserver.pas 上面配置文件中的mysql可以自定义，客户端同步的时候要用到。上面的认证用户，必须是系统存在的用户。接下来创建密码文件/etc/backserver.pas123$ sudo touch /etc/backserver.pas$ sudo chown root:root /etc/backserver.pas$ sudo chmod 600 /etc/backserver.pas 然后在里面加入ldongxu:ldongxu每个用户一行，冒号前面是用户名，后面是密码，然后启动服务1$ sudo rsync --daemon --config=/etc/rsyncd.conf 这样服务端就算搭建好了，可以把命令加入到开机启动1$ echo &apos;rsync --daemon --config=/etc/rsyncd.conf&apos; &gt;&gt; /etc/rc.d/rc.local 客户端假设我们要把刚刚服务器端的/home/ldongxu/backup/mysql同步下来。先创建密码文件，用于同步时的验证12$ touch ~/rsyncd.secrets$ chmod 600 ~/rsyncd.secrets 这个文件只要放密码就可以了，在这个例子中，则是放入1ldongxu 然后运行1$ rsync -avz --delete --password-file=/xxx/rsyncd.secrets clinyong@your_ip::mysql destination 把server_ip换成自己服务器的ip地址，mysql就是在服务器端的配置文件填写的字段，destination换成本地路径，这样子就能把文件同步下来了。 把命令加入到crontab，让其每天同步一次，运行crontab -e，在最后一行加入100 00 * * * rsync -avz --delete --password-file=/etc/rsyncd.secrets ldongxu@server_ip::mysql destination 语法123456rsync [OPTION]... SRC DEST rsync [OPTION]... SRC [USER@]host:DEST rsync [OPTION]... [USER@]HOST:SRC DEST rsync [OPTION]... [USER@]HOST::SRC DEST rsync [OPTION]... SRC [USER@]HOST::DEST rsync [OPTION]... rsync://[USER@]HOST[:PORT]/SRC [DEST] 对应于以上六种命令格式，rsync有六种不同的工作模式： 拷贝本地文件。当SRC和DES路径信息都不包含有单个冒号”:”分隔符时就启动这种工作模式。如：rsync -a /data /backup 使用一个远程shell程序(如rsh、ssh)来实现将本地机器的内容拷贝到远程机器。当DST路径地址包含单个冒号”:”分隔符时启动该模式。如：rsync -avz *.c foo:src 使用一个远程shell程序(如rsh、ssh)来实现将远程机器的内容拷贝到本地机器。当SRC地址路径包含单个冒号”:”分隔符时启动该模式。如：rsync -avz foo:src/bar /data 从远程rsync服务器中拷贝文件到本地机。当SRC路径信息包含”::”分隔符时启动该模式。如：rsync -av root@192.168.78.192::www /databack 从本地机器拷贝文件到远程rsync服务器中。当DST路径信息包含”::”分隔符时启动该模式。如：rsync -av /databack root@192.168.78.192::www 列远程机的文件列表。这类似于rsync传输，不过只要在命令中省略掉本地机信息即可。如：rsync -v rsync://192.168.78.192/www 选项1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859-v, --verbose 详细模式输出。 -q, --quiet 精简输出模式。 -c, --checksum 打开校验开关，强制对文件传输进行校验。 -a, --archive 归档模式，表示以递归方式传输文件，并保持所有文件属性，等于-rlptgoD。 -r, --recursive 对子目录以递归模式处理。 -R, --relative 使用相对路径信息。 -b, --backup 创建备份，也就是对于目的已经存在有同样的文件名时，将老的文件重新命名为~filename。可以使用--suffix选项来指定不同的备份文件前缀。--backup-dir 将备份文件(如~filename)存放在在目录下。 -suffix=SUFFIX 定义备份文件前缀。 -u, --update 仅仅进行更新，也就是跳过所有已经存在于DST，并且文件时间晚于要备份的文件，不覆盖更新的文件。 -l, --links 保留软链结。 -L, --copy-links 想对待常规文件一样处理软链结。 --copy-unsafe-links 仅仅拷贝指向SRC路径目录树以外的链结。 --safe-links 忽略指向SRC路径目录树以外的链结。 -H, --hard-links 保留硬链结。 -p, --perms 保持文件权限。 -o, --owner 保持文件属主信息。 -g, --group 保持文件属组信息。 -D, --devices 保持设备文件信息。 -t, --times 保持文件时间信息。 -S, --sparse 对稀疏文件进行特殊处理以节省DST的空间。 -n, --dry-run现实哪些文件将被传输。 -w, --whole-file 拷贝文件，不进行增量检测。 -x, --one-file-system 不要跨越文件系统边界。 -B, --block-size=SIZE 检验算法使用的块尺寸，默认是700字节。 -e, --rsh=command 指定使用rsh、ssh方式进行数据同步。 --rsync-path=PATH 指定远程服务器上的rsync命令所在路径信息。 -C, --cvs-exclude 使用和CVS一样的方法自动忽略文件，用来排除那些不希望传输的文件。 --existing 仅仅更新那些已经存在于DST的文件，而不备份那些新创建的文件。 --delete 删除那些DST中SRC没有的文件。 --delete-excluded 同样删除接收端那些被该选项指定排除的文件。 --delete-after 传输结束以后再删除。 --ignore-errors 及时出现IO错误也进行删除。 --max-delete=NUM 最多删除NUM个文件。 --partial 保留那些因故没有完全传输的文件，以是加快随后的再次传输。 --force 强制删除目录，即使不为空。 --numeric-ids 不将数字的用户和组id匹配为用户名和组名。 --timeout=time ip超时时间，单位为秒。 -I, --ignore-times 不跳过那些有同样的时间和长度的文件。 --size-only 当决定是否要备份文件时，仅仅察看文件大小而不考虑文件时间。 --modify-window=NUM 决定文件是否时间相同时使用的时间戳窗口，默认为0。 -T --temp-dir=DIR 在DIR中创建临时文件。--compare-dest=DIR 同样比较DIR中的文件来决定是否需要备份。 -P 等同于 --partial。 --progress 显示备份过程。 -z, --compress 对备份的文件在传输时进行压缩处理。 --exclude=PATTERN 指定排除不需要传输的文件模式。 --include=PATTERN 指定不排除而需要传输的文件模式。 --exclude-from=FILE 排除FILE中指定模式的文件。 --include-from=FILE 不排除FILE指定模式匹配的文件。 --version 打印版本信息。 --address 绑定到特定的地址。 --config=FILE 指定其他的配置文件，不使用默认的rsyncd.conf文件。 --port=PORT 指定其他的rsync服务端口。 --blocking-io 对远程shell使用阻塞IO。 -stats 给出某些文件的传输状态。 --log-format=formAT 指定日志文件格式。 --password-file=FILE 从FILE中得到密码。 --bwlimit=KBPS 限制I/O带宽，KBytes per second。 -h, --help 显示帮助信息。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://ldongxu.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://ldongxu.github.io/tags/Linux/"},{"name":"rsync","slug":"rsync","permalink":"https://ldongxu.github.io/tags/rsync/"},{"name":"Linux文件同步","slug":"Linux文件同步","permalink":"https://ldongxu.github.io/tags/Linux文件同步/"}]},{"title":"使用MongoDB工具备份和还原(mongodump和mongorestore)","slug":"使用MongoDB工具备份和还原-mongodump和mongorestore","date":"2017-04-06T08:46:42.000Z","updated":"2018-07-06T12:33:08.043Z","comments":true,"path":"2017/04/06/使用MongoDB工具备份和还原-mongodump和mongorestore/","link":"","permalink":"https://ldongxu.github.io/2017/04/06/使用MongoDB工具备份和还原-mongodump和mongorestore/","excerpt":"MongoDB version：3.4之前已经搭建了mongodb副本集，主要结构是一主二从（其中的一个从节点为仲裁节点），mongodb复制集主要目的是为了故障转移，但是出于数据安全角度考虑，数据备份也是非常关键的。MongoDB的备份其实算是一个基本操作。具体使用操作建议参看官方文档，官方文档的介绍比较全面也会有相关的建议。","text":"MongoDB version：3.4之前已经搭建了mongodb副本集，主要结构是一主二从（其中的一个从节点为仲裁节点），mongodb复制集主要目的是为了故障转移，但是出于数据安全角度考虑，数据备份也是非常关键的。MongoDB的备份其实算是一个基本操作。具体使用操作建议参看官方文档，官方文档的介绍比较全面也会有相关的建议。 常见的备份方式：1、通过复制基础数据文件备份(使用文件系统快照备份数据文件)；2、通过mongodump工具备份； 通过mongodump工具备份mongodb官方文档关于‘通过mongodump工具备份’有一段描述： mongodump reads data from a MongoDB database and creates high fidelity BSON files which the mongorestore tool can use to populate a MongoDB database. mongodump and mongorestore are simple and efficient tools for backing up and restoring small MongoDB deployments, but are not ideal for capturing backups of larger systems.mongodump从MongoDB数据库读取数据，并创建高保真的BSON文件，这些文件可以使用mongorestore将数据库还原到MongoDB数据库。 mongodump和mongorestore是用于备份和恢复小型MongoDB部署的简单有效的工具，但不是较大系统的备份的理想选择。 mongodump only captures the documents in the database. The resulting backup is space efficient, but mongorestore or mongod must rebuild the indexes after restoring data.mongodump只捕获数据库中的文档。 生成的备份是空间有效的，但是mongorestore或mongod必须在还原数据后重建索引。 When connected to a MongoDB instance, mongodump can adversely affect mongod performance. If your data is larger than system memory, the queries will push the working set out of memory, causing page faults.当连接到MongoDB实例时，mongodump可能会对mongod性能产生不利影响。 如果您的数据大于系统内存，查询会将工作集推出内存，导致页面错误。 Applications can continue to modify data while mongodump captures the output. For replica sets, mongodump provides the –oplog option to include in its output oplog entries that occur during the mongodump operation. This allows the corresponding mongorestore operation to replay the captured oplog. To restore a backup created with –oplog, use mongorestore with the –oplogReplay option.当mongodump捕获输出时，应用程序可以继续修改数据。 对于副本集，mongodump提供–oplog选项，以便在其输出的oplog条目中包含mongodump操作期间发生的数据库操作。 这允许相应的mongorestore操作重播捕获的oplog。 要恢复使用–oplog创建的备份，请使用带有–oplogReplay选项的mongorestore。 mongodump的选项–oplog是一个值得一提的选项：注意这是replica set或者master/slave模式专用（standalone模式运行mongodb并不推荐）。它的实际作用是在导出的同时生成一个oplog.bson文件，存放在你开始进行dump到dump结束之间所有的oplog。简单地说，在replica set中oplog是一个定容集合（capped collection），它的默认大小是磁盘空间的5%（可以通过–oplogSizeMB参数修改），位于local库的db.oplog.rs，有兴趣可以看看里面到底有些什么内容。其中记录的是整个mongod实例一段时间内数据库的所有变更（插入/更新/删除）操作。oplog有一个非常重要的特性——幂等性（idempotent）。即对一个数据集合，使用oplog中记录的操作重放时，无论被重放多少次，其结果会是一样的。举例来说，如果oplog中记录的是一个插入操作，并不会因为你重放了两次，数据库中就得到两条相同的记录。这是一个很重要的特性，也是后面这些操作的基础。 回到主题上来，看看oplog.bson到底有什么作用。首先要明白的一个问题是数据之间互相有依赖性，比如集合A中存放了订单，集合B中存放了订单的所有明细，那么只有一个订单有完整的明细时才是正确的状态。假设在任意一个时间点，A和B集合的数据都是完整对应并且有意义的（对非关系型数据库要做到这点并不容易，且对于MongoDB来说这样的数据结构并非合理。但此处我们假设这个条件成立），那么如果A处于时间点x，而B处于x之后的一个时间点y时，可以想象A和B中的数据极有可能不对应而失去意义。 再回来看mongodump的操作。mongodump的进行过程中并不会把数据库锁死以保证整个库冻结在一个固定的时间点，这在业务上常常是不允许的。所以就有了dump的最终结果中A集合是10点整的状态，而B集合则是10点零1分的状态这种情况。这样的备份即使恢复回去，可以想象得到的结果恐怕意义有限。那么上面这个oplog.bson的意义就在这里体现出来了。如果在dump数据的基础上，再重做一遍oplog中记录的所有操作，这时的数据就可以代表dump结束时那个时间点（point-in-time）的数据库状态。这个结论成立的重要条件就是幂等性：已存在的数据，重做oplog不会重复；不存在的数据重做oplog就可以进入数据库。所以当做完截止到某个时间点的oplog时，数据库就恢复到了截止那个时间点的状态。 那么从别处而来的oplog呢？聪明如你可能已经想到，既然dump出的数据配合oplog就可以把数据库恢复到某个状态，那是不是拥有一份从某个时间点开始备份的dump数据，再加上从dump开始之后的oplog，如果oplog足够长，是不是就可以把数据库恢复到其后的任意状态了？是的！事实上replica set正是依赖oplog的重放机制在工作。当secondary第一次加入replica set时做的initial sync就相当于是在做mongodump，此后只需要不断地同步和重放oplog.rs中的数据，就达到了secondary与primary同步的目的。 既然oplog一直都在oplog.rs中存在，我们为什么还需要在mongodump时指定–oplog呢？需要的时候从oplog.rs中拿不就完了吗？答案是肯定的，你确实可以只dump数据，不需要oplog。在需要的时候可以再从oplog.rs中取。但前提是oplog时间窗口（忘了时间窗口概念的请往前翻）必须能够覆盖dump的开始时间。参考链接:http://www.cnblogs.com/yaoxing/p/mongodb-backup-rules.html mongodump几个例子数据库在本地27017端口上运行mongodump --db test --collection collection 需要认证，备份输出到指定目录mongodump --host mongodb1.example.net --port 37017 --username user --password pass --out /opt/backup/mongodump-2011-10-24 数据库备份到归档文件test.20150715.archive。不能将–archive选项与-out选项一起使用mongodump --archive=test.20150715.archive --db test 归档并压缩mongodump --archive=test.20150715.gz --gzip --db test 副本集备份（以副本集名称为前缀，mongodump将默认从主节点成员读取）mongodump --host &quot;replSet/rep1.example.net:27017,rep2.example.net:27017,rep3.example.net:27017&quot; 副本集备份（不包含副本集名称作为主机字符串的前缀，mongodump则默认从最近的节点读取。）mongodump --host &quot;rep1.example.net:27017,rep2.example.net:27017,rep3.example.net:27017&quot; mongodump --host &quot;replSet/rep1.example.net:27017,rep2.example.net:27017,rep3.example.net:27017&quot; --username user --password --oplog --gzip --out /home/data/mongobak mongorestore --host &quot;replSet/rep1.example.net:27017,rep2.example.net:27017,rep3.example.net:27017&quot; --username user --password --gzip --db test /home/data/mongobak mongodb备份和恢复角色admin数据库中包括了备份和还原数据的角色backup和restore。（只在admin库中存在）backup：提供备份数据所需的权限。 该角色提供了使用MongoDB Cloud Manager备份代理，Ops Manager备份代理或使用mongodump的足够权限。restore：提供使用mongorestore恢复数据所需的权限，而不使用–oplogReplay选项或没有system.profile集合数据。（如果使用–oplogReplay运行mongorestore，还原角色不足以重播oplog。 要重播oplog，请创建一个用户定义的角色。） 为了安全考虑，建议在admin中创建备份和恢复角色来执行数据备份和恢复操作。 mongodump/mongorestore与mongoexport/mongoimport的区别除了mongodump/mongorestore之外还有一对组合是mongoexport/mongoimport 区别在哪里？ mongoexport/mongoimport导入/导出的是JSON格式，而mongodump/mongorestore导入/导出的是BSON格式。JSON可读性强但体积较大，BSON则是二进制文件，体积小但对人类几乎没有可读性。在一些mongodb版本之间，BSON格式可能会随版本不同而有所不同，所以不同版本之间用mongodump/mongorestore可能不会成功，具体要看版本之间的兼容性。当无法使用BSON进行跨版本的数据迁移的时候，使用JSON格式即mongoexport/mongoimport是一个可选项。跨版本的mongodump/mongorestore个人并不推荐，实在要做请先检查文档看两个版本是否兼容（大部分时候是的）。JSON虽然具有较好的跨版本通用性，但其只保留了数据部分，不保留索引，账户等其他基础信息。使用时应该注意。总之，这两套工具在实际使用中各有优势，应该根据应用场景选择使用（好像跟没说一样）。但严格地说，mongoexport/mongoimport的主要作用还是导入/导出数据时使用，并不是一个真正意义上的备份工具。所以这里也不展开介绍了。","categories":[{"name":"Mongodb","slug":"Mongodb","permalink":"https://ldongxu.github.io/categories/Mongodb/"}],"tags":[{"name":"Mongodb备份还原","slug":"Mongodb备份还原","permalink":"https://ldongxu.github.io/tags/Mongodb备份还原/"}]},{"title":"Linux下crontab定时任务","slug":"Linux下crontab定时任务","date":"2017-03-30T10:02:33.000Z","updated":"2018-07-06T12:33:08.042Z","comments":true,"path":"2017/03/30/Linux下crontab定时任务/","link":"","permalink":"https://ldongxu.github.io/2017/03/30/Linux下crontab定时任务/","excerpt":"因为需要在Linux下定时对数据库做备份，所以对Linux的crontab服务做了一些简单的了解。以下内容是在实际操作过程中遇到的一些问题及相关技术翻案，包括crontab简单了解、怎么用vi打开编辑crontab、crontab时间表达式、定时任务输出重定向等问题。","text":"因为需要在Linux下定时对数据库做备份，所以对Linux的crontab服务做了一些简单的了解。以下内容是在实际操作过程中遇到的一些问题及相关技术翻案，包括crontab简单了解、怎么用vi打开编辑crontab、crontab时间表达式、定时任务输出重定向等问题。 Linux下的定时任务设置crontab简介Linux下的任务调度分为两类，系统任务调度和用户任务调度。系统任务调度：系统周期性所要执行的工作，比如写缓存数据到硬盘、日志清理等。在/etc目录下有一个crontab文件，这个就是系统任务调度的配置文件。/etc/crontab文件包括下面几行： 123456789101112131415# /etc/crontab: system-wide crontab# Unlike any other crontab you don&apos;t have to run the `crontab&apos;# command to install the new version when you edit this file# and files in /etc/cron.d. These files also have username fields,# that none of the other crontabs do.SHELL=/bin/shPATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/binMAILTO=&quot;&quot;HOME=/# m h dom mon dow user command17 * * * * root cd / &amp;&amp; run-parts --report /etc/cron.hourly25 6 * * * root test -x /usr/sbin/anacron || ( cd / &amp;&amp; run-parts --report /etc/cron.daily )47 6 * * 7 root test -x /usr/sbin/anacron || ( cd / &amp;&amp; run-parts --report /etc/cron.weekly )52 6 1 * * root test -x /usr/sbin/anacron || ( cd / &amp;&amp; run-parts --report /etc/cron.monthly ) 前四行是用来配置crond任务运行的环境变量，第一行SHELL变量指定了系统要使用哪个shell，这里是bash，第二行PATH变量指定了系统执行命令的路径，第三行MAILTO变量指定了crond的任务执行信息将通过电子邮件发送给root用户，如果MAILTO变量的值为空，则表示不发送任务执行信息给用户，第四行的HOME变量指定了在执行命令或者脚本时使用的主目录。 用户任务调度：用户定期要执行的工作，比如用户数据备份、定时邮件提醒等。用户可以使用 crontab 工具来定制自己的计划任务。所有用户定义的crontab 文件都被保存在 /var/spool/cron目录中。其文件名与用户名一致。 使用者权限文件：/var/spool/cron：所有用户定义的crontab 文件都被保存在目录中，其文件名与用户名一致。/etc/cron.deny：该文件中所列用户不允许使用crontab命令。/etc/cron.allow：该文件中所列用户允许使用crontab命令，优先于/etc/cron.deny 设置crontab用vi打开编辑：编辑.profile文件,增加EDITOR=vi;export EDITOR 或 直接在命令行输入 EDITOR=vi;export EDITOR 判断方法： $ which $EDITOR $ 如果该行显示为空，那么你就需要执行下面的两个语句了。 $ EDITOR=vi $ export EDITOR crontab的时间表达式基本格式 :12* * * * * command分 时 日 月 周 命令 几个例子：12345678910111213141516171、每分钟执行一次 * * * * * 2、每隔一小时执行一次 00 * * * * or * */1 * * * (/表示频率)3、每小时的15和30分各执行一次 15,45 * * * * （,表示并列）4、在每天上午 8- 11时中间每小时 15 ，45分各执行一次 15,45 8-11 * * * command （-表示范围）5、每个星期一的上午8点到11点的第3和第15分钟执行 3,15 8-11 * * 1 command6、每隔两天的上午8点到11点的第3和第15分钟执行 3,15 8-11 */2 * * command crontab命令介绍查看crontab服务状态： service cron status手动启动crontab服务： service cron start手动停止crontab服务： service cron stop 使用方式 :1234567891011crontab [-u user] file：file是命令文件的名字,表示将file做为crontab的任务列表文件并载入crontab。如果在命令行中没有指定这个文件，crontab命令将接受标准输入（键盘）上键入的命令，并将它们载入crontab。crontab -u [user]：用来设定某个用户的crontab服务，例如，“-u ixdba”表示设定ixdba用户的crontab服务，此参数一般由root用户来运行。crontab -e：编辑某个用户的crontab文件内容。如果不指定用户，则表示编辑当前用户的crontab文件。crontab -l：显示某个用户的crontab文件内容，如果不指定用户，则表示显示当前用户的crontab文件内容。crontab -r：从/var/spool/cron目录中删除某个用户的crontab文件，如果不指定用户，则默认删除当前用户的crontab文件。crontab -i：在删除用户的crontab文件时给确认提示。 常用crontab命令：查看当前用户的定时任务： [root@AY1404010929194851d3Z:~]# crontab -l查看指定用户的定时任务： [root@AY1404010929194851d3Z:~]# crontab -uroot -l追加crontab定时任务： [root@AY1404010929194851d3Z:~]# crontab -e 注：定时任务结尾加 &gt;/dev/null 2&gt;&amp;1(在调试好脚本程序后，应尽量把DEBUG及命令输出的内容信息屏蔽掉，如果确实需要输出日志，可定向到日志文件里，避免产生系统垃圾。)如： 123[root@angelT ~]# crontab -l#backup www to /backup00 00 * * * /bin/sh /server/scripts/www_bak.sh &gt;/dev/null 2&gt;&amp;1 有关/dev/null的说明：/dev/null为特殊的字符设备文件，表示黑洞设备或空设备。>/dev/null 2&gt;&amp;1的作用：如果定时任务规范结尾不加 &gt;/dev/null 2&gt;&amp;1,很容易导致硬盘inode空间被占满，从而系统服务不正常（var/spool/clientmqueue邮件临时队列目录，垃圾文件存放于此，如果是centos 6.4系统，默认不装sendmail服务，所以不会有这个目录。） 有关重定向的说明：123456789101112&gt;或1&gt; 输出重定向：把前面输出的东西输入到后边的文件中，会删除文件原有内容。&gt;&gt;或1&gt;&gt;追加重定向：把前面输出的东西追加到后边的文件中，不会删除文件原有内容。&lt;或&lt;0 输入重定向：输入重定向用于改变命令的输入，指定输入内容，后跟文件名。&lt;&lt;或&lt;&lt;0输入重定向：后跟字符串，用来表示“输入结束”，也可用ctrl+d来结束输入。2&gt; 错误重定向：把错误信息输入到后边的文件中，会删除文件原有内容。2&gt;&gt; 错误追加重定向：把错误信息追加到后边的文件中，不会删除文件原有内容。标准输入（stdin）：代码为0，使用&lt;或&lt;&lt;。标准输出（stdout）:代码为1，使用&gt;或&gt;&gt;。正常的输出。标准错误输出（sederr）：代码为2，使用2&gt;或2&gt;&gt;。特殊：2&gt;&amp;1就是把标准错误重定向到标准输出（&gt;&amp;）。&gt;/dev/null 2&gt;&amp;1 等价于 1&gt;/dev/null 2&gt;/dev/null","categories":[{"name":"Linux","slug":"Linux","permalink":"https://ldongxu.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://ldongxu.github.io/tags/Linux/"},{"name":"crontab","slug":"crontab","permalink":"https://ldongxu.github.io/tags/crontab/"}]},{"title":"Linux定时任务定时备份mongodb和删除历史备份shell脚本","slug":"Linux定时任务定时备份mongodb和删除历史备份shell脚本","date":"2017-03-29T09:54:24.000Z","updated":"2018-07-06T12:33:08.042Z","comments":true,"path":"2017/03/29/Linux定时任务定时备份mongodb和删除历史备份shell脚本/","link":"","permalink":"https://ldongxu.github.io/2017/03/29/Linux定时任务定时备份mongodb和删除历史备份shell脚本/","excerpt":"Linux下mongodb数据备份shell脚本 常用crontab命令： mongodb的mongodump、mongorestore几种执行方式","text":"Linux下mongodb数据备份shell脚本 常用crontab命令： mongodb的mongodump、mongorestore几种执行方式 一、在linux下面使用shell脚本执行Mongodb数据文件备份代码如下：12345678910111213141516171819202122232425262728293031323334353637#!/bin/bashsourcepath=&apos;/app/mongodb&apos;/bintargetpath=&apos;/yoyodata/mongobak&apos;nowtime=$(date +%Y%m%d)expiretime=$(date -d &apos;-7 days&apos; &quot;+%Y%m%d&quot;) start()&#123; $&#123;sourcepath&#125;/mongodump --host 127.0.0.1 --port 27017 --out $&#123;targetpath&#125;/$&#123;nowtime&#125;&#125;delete()&#123; if [ -d &quot;$&#123;targetpath&#125;/$&#123;expiretime&#125;/&quot; ] then rm -rf &quot;$&#123;targetpath&#125;/$&#123;expiretime&#125;/&quot; echo &quot;=======$&#123;targetpath&#125;/$&#123;expiretime&#125;/===delete successfully!==&quot; fi echo &quot;===no $expiretime need to delete===&quot;&#125;execute()&#123; start if [ $? -eq 0 ] then echo &quot;back successfully!&quot; delete else echo &quot;back failure!&quot; fi&#125; if [ ! -d &quot;$&#123;targetpath&#125;/$&#123;nowtime&#125;/&quot; ]then mkdir $&#123;targetpath&#125;/$&#123;nowtime&#125;fiexecuteecho &quot;============== back end $&#123;nowtime&#125; ==============&quot; 二、常用crontab命令：查看当前用户的定时任务：[root@AY1404010929194851d3Z:~]# crontab -l查看指定用户的定时任务：[root@AY1404010929194851d3Z:~]# crontab -uroot -l追加crontab定时任务：[root@AY1404010929194851d3Z:~]# crontab -eLinux下crontab定时任务 三、mongodb的mongorestore数据还原 几种mongodb数据备份方式： 12345678无账号、密码mongodump -o backup #备份所有数据库到backup目录下，每个数据库一个文件，除local数据库外。mongodump -d abc -o backup #备份abc数据库到backup目录下。mongodump -d abc -c ddd -o backup #备份abc数据库下的ddd集合。#有账号、密码mongodump -udba -pdba -d abc -c ddd -o backup #备份abc数据库下的ddd集合。mongodump --host=127.0.0.1 --port=27017 -udba -p --db=abc --collection=ddd -o backup 几种mongodb数据恢复方式 123456789mongorestore -udba -pdba -d abc backup/abc #还原abc数据库。mongorestore -udba -pdba -d abc --drop backup/abc #还原之前先删除原来数据库（集合）。mongorestore -udba -pdba -d abc -c ddd --drop backup/abc/ddd.bson #还原abc库中的ddd集合。mongorestore --host=127.0.0.1 --port=27017 -udba -pdba -d abc -c test --drop backup/abc/test.bson #还原abc库中的test集合。mongorestore --host=127.0.0.1 --port=27017 -udba -pdba -d abc -c ooo --drop backup/abc/test.bson #还原abc库中的test集合到ooo集合。","categories":[{"name":"Mongodb","slug":"Mongodb","permalink":"https://ldongxu.github.io/categories/Mongodb/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://ldongxu.github.io/tags/Linux/"},{"name":"crontab","slug":"crontab","permalink":"https://ldongxu.github.io/tags/crontab/"},{"name":"Mongodb","slug":"Mongodb","permalink":"https://ldongxu.github.io/tags/Mongodb/"},{"name":"shell","slug":"shell","permalink":"https://ldongxu.github.io/tags/shell/"}]},{"title":"nginx负载均衡配置详解","slug":"nginx负载均衡配置详解","date":"2017-03-28T02:55:21.000Z","updated":"2018-07-19T10:02:28.974Z","comments":true,"path":"2017/03/28/nginx负载均衡配置详解/","link":"","permalink":"https://ldongxu.github.io/2017/03/28/nginx负载均衡配置详解/","excerpt":"nginx负载均衡反向代理配置示例详解：","text":"nginx负载均衡反向代理配置示例详解：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394worker_processes 2;events &#123; worker_connections 1024; &#125;http &#123; include mime.types; default_type application/octet-stream; # upstream 配置一组后端服务器， # 请求转发到upstream后，nginx按策略将请求指派出某一服务器 # 即配置用于负载均衡的服务器群信息 upstream backends &#123; #均衡策略 #none 轮询（权重由weight决定） #ip_hash #fair #url_hash server 192.168.1.62:8080; server 192.168.1.63; # weight:权重，值越高负载越大； # server 192.168.1.64 weight=5; # backup：备份机，只有非备份机都挂掉了才启用； server 192.168.1.64 backup; # down: 停机标志，不会被访问 server 192.168.1.65 down; # max_fails:达到指定次数认为服务器挂掉； # fail_timeout:挂掉之后过多久再去测试是否已恢复 server 192.168.1.66 max_fails=2 fail_timeout=60s; &#125; server &#123; listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; root html; index index.html index.htm; &#125; # 反向代理设置，将所有/proxy_test/路径下请求发给本机上的tomcat location /proxy_test/ &#123; proxy_pass http://localhost:8080; &#125; # 负载均衡设置，将所有jsp请求发送到upstream backends指定的服务器群上 location ~ \\.jsp$ &#123; proxy_pass http://backends; # 真实的客户端IP proxy_set_header X-Real-IP $remote_addr; # 请求头中Host信息 proxy_set_header Host $host; # 代理路由信息，此处取IP有安全隐患 proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; # 真实的用户访问协议 proxy_set_header X-Forwarded-Proto $scheme; # 默认值default， # 后端response 302时 tomcat header中location的host是http://192.168.1.62:8080 # 因为tomcat收到的请求是nginx发过去的, nginx发起的请求url host是http://192.168.1.62:8080 # 设置为default后，nginx自动把响应头中location host部分替换成当前用户请求的host部分 # 网上很多教程将此值设置成 off，禁用了替换， # 这样用户浏览器收到302后跳到http://192.168.1.62:8080，直接将后端服务器暴露给浏览器 # 所以除非特殊需要，不要设置这种画蛇添足的配置 proxy_redirect default; &#125; # 一个url重写的例子，浏览器请求 /page.go时，url被重写成/test/page.jsp location ~ \\.go$ &#123; rewrite ^(.*)\\.go$ /test/$1\\.jsp last; &#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; &#125;&#125;","categories":[{"name":"nginx","slug":"nginx","permalink":"https://ldongxu.github.io/categories/nginx/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://ldongxu.github.io/tags/nginx/"}]},{"title":"Gson解析空字符串异常的处理","slug":"Gson解析空字符串异常的处理","date":"2016-12-30T02:16:00.000Z","updated":"2018-07-06T12:33:08.040Z","comments":true,"path":"2016/12/30/Gson解析空字符串异常的处理/","link":"","permalink":"https://ldongxu.github.io/2016/12/30/Gson解析空字符串异常的处理/","excerpt":"面对一些不规范的json,我们用Gson解析经常会抛出各种异常导致程序崩溃,这里可以采取一些措施来避免。","text":"面对一些不规范的json,我们用Gson解析经常会抛出各种异常导致程序崩溃,这里可以采取一些措施来避免。 Json异常情况先来看一个后台返回的json正常情况下json:12345678&#123; &quot;code&quot;:0, &quot;msg&quot;:&quot;ok&quot;, &quot;data&quot;:&#123; &quot;id&quot;:5638, &quot;newsId&quot;:5638 &#125;&#125; data部分对应的实体类: 1234567891011121314151617181920public class JsonBean &#123; private int id; private int newsId; public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public int getNewsId() &#123; return newsId; &#125; public void setNewsId(int newsId) &#123; this.newsId = newsId; &#125;&#125; 异常情况json(后台数据库newsId字段未查询到对应数据):12345678&#123; &quot;code&quot;:0, &quot;msg&quot;:&quot;ok&quot;, &quot;data&quot;:&#123; &quot;id&quot;:5638, &quot;newsId&quot;:&quot;&quot; &#125;&#125; 这样Gson在解析时就会抛出解析错误的异常,程序崩溃,原因是无法将””转化为int。 json异常的处理我们期望在后台返回的json异常时,也能解析成功,空值对应的转换为默认值,如:newsId=0;这里排除掉后台开发人员输出时给你做矫正,还是得靠自己。我们写一个针对int值的类型转换器,需要实现Gson的JsonSerializer接口和JsonDeserializer,即序列化和反序列化接口：12345678910111213141516171819202122public class IntegerDefault0Adapter implements JsonSerializer&lt;Integer&gt;, JsonDeserializer&lt;Integer&gt; &#123; @Override public Integer deserialize(JsonElement json, Type typeOfT, JsonDeserializationContext context) throws JsonParseException &#123; try &#123; if (json.getAsString().equals(\"\") || json.getAsString().equals(\"null\")) &#123;//定义为int类型,如果后台返回\"\"或者null,则返回0 return 0; &#125; &#125; catch (Exception ignore) &#123; &#125; try &#123; return json.getAsInt(); &#125; catch (NumberFormatException e) &#123; throw new JsonSyntaxException(e); &#125; &#125; @Override public JsonElement serialize(Integer src, Type typeOfSrc, JsonSerializationContext context) &#123; return new JsonPrimitive(src); &#125;&#125; 同理Long及Double类型double=&gt;123456789101112131415161718192021public class DoubleDefault0Adapter implements JsonSerializer&lt;Double&gt;, JsonDeserializer&lt;Double&gt; &#123; @Override public Double deserialize(JsonElement json, Type typeOfT, JsonDeserializationContext context) throws JsonParseException &#123; try &#123; if (json.getAsString().equals(\"\") || json.getAsString().equals(\"null\")) &#123;//定义为double类型,如果后台返回\"\"或者null,则返回0.00 return 0.00; &#125; &#125; catch (Exception ignore) &#123; &#125; try &#123; return json.getAsDouble(); &#125; catch (NumberFormatException e) &#123; throw new JsonSyntaxException(e); &#125; &#125; @Override public JsonElement serialize(Double src, Type typeOfSrc, JsonSerializationContext context) &#123; return new JsonPrimitive(src); &#125;&#125; long=&gt;12345678910111213141516171819202122public class LongDefault0Adapter implements JsonSerializer&lt;Long&gt;, JsonDeserializer&lt;Long&gt; &#123; @Override public Long deserialize(JsonElement json, Type typeOfT, JsonDeserializationContext context) throws JsonParseException &#123; try &#123; if (json.getAsString().equals(\"\") || json.getAsString().equals(\"null\")) &#123;//定义为long类型,如果后台返回\"\"或者null,则返回0 return 0l; &#125; &#125; catch (Exception ignore) &#123; &#125; try &#123; return json.getAsLong(); &#125; catch (NumberFormatException e) &#123; throw new JsonSyntaxException(e); &#125; &#125; @Override public JsonElement serialize(Long src, Type typeOfSrc, JsonSerializationContext context) &#123; return new JsonPrimitive(src); &#125;&#125; 123456789101112131415161718192021/** * 增加后台返回\"\"和\"null\"的处理 * 1.int=&gt;0 * 2.double=&gt;0.00 * 3.long=&gt;0L * * @return */public static Gson buildGson() &#123; if (gson == null) &#123; gson = new GsonBuilder() .registerTypeAdapter(Integer.class, new IntegerDefault0Adapter()) .registerTypeAdapter(int.class, new IntegerDefault0Adapter()) .registerTypeAdapter(Double.class, new DoubleDefault0Adapter()) .registerTypeAdapter(double.class, new DoubleDefault0Adapter()) .registerTypeAdapter(Long.class, new LongDefault0Adapter()) .registerTypeAdapter(long.class, new LongDefault0Adapter()) .create(); &#125; return gson;&#125; 再也不会因为后台json字段为空的情况崩溃了。 数组类型的字段解析异常 关于数组类型的字段解析异常,尝试了一些方案,但最后都存在问题。异常示例=&gt;正常json: { &quot;code&quot;:0, &quot;msg&quot;:&quot;ok&quot;, &quot;data&quot;:[ //约定为数组 { &quot;id&quot;:5638, &quot;newsId&quot;:5638 } ] } 异常json: { &quot;code&quot;:0, &quot;msg&quot;:&quot;ok&quot;, &quot;data&quot;:{} //返回为对象或者空字符串 }","categories":[{"name":"Java","slug":"Java","permalink":"https://ldongxu.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://ldongxu.github.io/tags/Java/"},{"name":"Gson","slug":"Gson","permalink":"https://ldongxu.github.io/tags/Gson/"}]},{"title":"Tomcat调优及JVM参数优化","slug":"Tomcat调优及JVM参数优化","date":"2016-06-22T08:20:39.000Z","updated":"2018-07-06T12:33:08.042Z","comments":true,"path":"2016/06/22/Tomcat调优及JVM参数优化/","link":"","permalink":"https://ldongxu.github.io/2016/06/22/Tomcat调优及JVM参数优化/","excerpt":"&emsp;Tomcat的缺省配置是不能稳定长期运行的，也就是不适合生产环境，它会死机，让你不断重新启动，甚至在午夜时分唤醒你。对于操作系统优化来说，是尽可能的增大可使用的内存容量、提高CPU的频率，保证文件系统的读写速率等。经过压力测试验证，在并发连接很多的情况下，CPU的处理能力越强，系统运行速度越快。&emsp;Tomcat的优化不像其它软件那样，简简单单的修改几个参数就可以了，它的优化主要有三方面，分为系统优化，Tomcat 本身的优化，Java 虚拟机（JVM）调优。系统优化就不在介绍了，接下来就详细的介绍一下 Tomcat 本身与 JVM 优化，以 Tomcat 7 为例。","text":"&emsp;Tomcat的缺省配置是不能稳定长期运行的，也就是不适合生产环境，它会死机，让你不断重新启动，甚至在午夜时分唤醒你。对于操作系统优化来说，是尽可能的增大可使用的内存容量、提高CPU的频率，保证文件系统的读写速率等。经过压力测试验证，在并发连接很多的情况下，CPU的处理能力越强，系统运行速度越快。&emsp;Tomcat的优化不像其它软件那样，简简单单的修改几个参数就可以了，它的优化主要有三方面，分为系统优化，Tomcat 本身的优化，Java 虚拟机（JVM）调优。系统优化就不在介绍了，接下来就详细的介绍一下 Tomcat 本身与 JVM 优化，以 Tomcat 7 为例。 一、Tomcat 本身优化Tomcat 的自身参数的优化，这块很像 ApacheHttp Server。修改一下 xml 配置文件中的参数，调整最大连接数，超时等。此外，我们安装 Tomcat 时，优化就已经开始了。 1、工作方式选择为了提升性能，首先就要对代码进行动静分离，让 Tomcat 只负责 jsp 文件的解析工作。如采用 Nginx 和 Tomcat 的整合方式，实现动静分离。 2、Connector 连接器的配置之前文件介绍过的 Tomcat 连接器的三种方式： bio、nio 和 apr，三种方式性能差别很大，apr 的性能最优， bio 的性能最差。而 Tomcat 7 使用的 Connector 默认就启用的 Apr 协议，但需要系统安装 Apr 库，否则就会使用 bio 方式。 3、配置文件优化配置文件优化其实就是对 server.xml 优化，可以提大大提高 Tomcat 的处理请求的能力，下面我们来看 Tomcat 容器内的优化。 默认配置下，Tomcat 会为每个连接器创建一个绑定的线程池（最大线程数 200），服务启动时，默认创建了 5 个空闲线程随时等待用户请求。 首先，打开 ${TOMCAT_HOME}/conf/server.xml，搜索【&lt;Executor name=&quot;tomcatThreadPool&quot;&gt;】，开启并调整为1&lt;Executor name=&quot;tomcatThreadPool&quot; namePrefix=&quot;catalina-exec-&quot; maxThreads=&quot;500&quot; minSpareThreads=&quot;20&quot; maxSpareThreads=&quot;50&quot; maxIdleTime=&quot;60000&quot;/&gt; 注意， Tomcat 7 在开启线程池前，一定要安装好 Apr 库，并可以启用，否则会有错误报出，shutdown.sh 脚本无法关闭进程。 然后，修改&lt;Connector …&gt;节点，增加 executor 属性，搜索【port=&quot;8080&quot;】，调整为1234567891011121314&lt;Connector executor=&quot;tomcatThreadPool&quot; port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; URIEncoding=&quot;UTF-8&quot; connectionTimeout=&quot;30000&quot; enableLookups=&quot;false&quot; disableUploadTimeout=&quot;false&quot; connectionUploadTimeout=&quot;150000&quot; acceptCount=&quot;300&quot; keepAliveTimeout=&quot;120000&quot; maxKeepAliveRequests=&quot;1&quot; compression=&quot;on&quot; compressionMinSize=&quot;2048&quot; compressableMimeType=&quot;text/html,text/xml,text/javascript,text/css,text/plain,image/gif,image/jpg,image/png&quot; redirectPort=&quot;8443&quot; /&gt; maxThreads :Tomcat 使用线程来处理接收的每个请求，这个值表示 Tomcat 可创建的最大的线程数，默认值是 200；minSpareThreads：最小空闲线程数，Tomcat 启动时的初始化的线程数，表示即使没有人使用也开这么多空线程等待，默认值是 10；maxSpareThreads：最大备用线程数，一旦创建的线程超过这个值，Tomcat 就会关闭不再需要的 socket 线程。 上边配置的参数，最大线程 500（一般服务器足以），要根据自己的实际情况合理设置，设置越大会耗费内存和 CPU，因为 CPU 疲于线程上下文切换，没有精力提供请求服务了，最小空闲线程数 20，线程最大空闲时间 60 秒，当然允许的最大线程连接数还受制于操作系统的内核参数设置，设置多大要根据自己的需求与环境。当然线程可以配置在“tomcatThreadPool”中，也可以直接配置在“Connector”中，但不可以重复配置。 URIEncoding：指定 Tomcat 容器的 URL 编码格式，语言编码格式这块倒不如其它 WEB 服务器软件配置方便，需要分别指定。 connnectionTimeout： 网络连接超时，单位：毫秒，设置为 0 表示永不超时，这样设置有隐患的。通常可设置为 30000 毫秒，可根据检测实际情况，适当修改。 enableLookups： 是否反查域名，以返回远程主机的主机名，取值为：true 或 false，如果设置为false，则直接返回IP地址，为了提高处理能力，应设置为 false。 disableUploadTimeout：上传时是否使用超时机制。 connectionUploadTimeout：上传超时时间，毕竟文件上传可能需要消耗更多的时间，这个根据你自己的业务需要自己调，以使Servlet有较长的时间来完成它的执行，需要与上一个参数一起配合使用才会生效。 acceptCount：指定当所有可以使用的处理请求的线程数都被使用时，可传入连接请求的最大队列长度，超过这个数的请求将不予处理，默认为100个。 keepAliveTimeout：长连接最大保持时间（毫秒），表示在下次请求过来之前，Tomcat 保持该连接多久，默认是使用 connectionTimeout 时间，-1 为不限制超时。maxKeepAliveRequests：表示在服务器关闭之前，该连接最大支持的请求数。超过该请求数的连接也将被关闭，1表示禁用，-1表示不限制个数，默认100个，一般设置在100~200之间。compression：是否对响应的数据进行 GZIP 压缩，off：表示禁止压缩；on：表示允许压缩（文本将被压缩）、force：表示所有情况下都进行压缩，默认值为off，压缩数据后可以有效的减少页面的大小，一般可以减小1/3左右，节省带宽。 compressionMinSize：表示压缩响应的最小值，只有当响应报文大小大于这个值的时候才会对报文进行压缩，如果开启了压缩功能，默认值就是2048。compressableMimeType：压缩类型，指定对哪些类型的文件进行数据压缩。 noCompressionUserAgents=”gozilla, traviata”： 对于以下的浏览器，不启用压缩。 如果已经对代码进行了动静分离，静态页面和图片等数据就不需要 Tomcat 处理了，那么也就不需要配置在 Tomcat 中配置压缩了。以上是一些常用的配置参数属性，当然还有好多其它的参数设置，还可以继续深入的优化，HTTP Connector 与 AJP Connector 的参数属性值，可以参考官方文档的详细说明： https://tomcat.apache.org/tomcat-7.0-doc/config/http.html https://tomcat.apache.org/tomcat-7.0-doc/config/ajp.html 二、JVM 优化&emsp;Tomcat 启动命令行中的优化参数，就是 JVM 的优化 。Tomcat 首先跑在 JVM 之上的，因为它的启动其实也只是一个 java 命令行，首先我们需要对这个 JAVA 的启动命令行进行调优。不管是 YGC 还是 Full GC，GC 过程中都会对导致程序运行中中断，正确的选择不同的 GC 策略，调整 JVM、GC 的参数，可以极大的减少由于 GC 工作，而导致的程序运行中断方面的问题，进而适当的提高 Java 程序的工作效率。但是调整 GC 是以个极为复杂的过程，由于各个程序具备不同的特点，如：web 和 GUI 程序就有很大区别（Web可以适当的停顿，但GUI停顿是客户无法接受的），而且由于跑在各个机器上的配置不同（主要 cup 个数，内存不同），所以使用的 GC 种类也会不同。 1、JVM 参数配置方法Tomcat 的启动参数位于安装目录 ${JAVA_HOME}/bin目录下，Linux 操作系统就是 catalina.sh 文件。JAVA_OPTS，就是用来设置 JVM 相关运行参数的变量，还可以在 CATALINA_OPTS 变量中设置。关于这 2 个变量，还是多少有些区别的： JAVA_OPTS：用于当 Java 运行时选项“start”、“stop”或“run”命令执行。 CATALINA_OPTS：用于当 Java 运行时选项“start”或“run”命令执行。 为什么有两个不同的变量？它们之间都有什么区别呢？ 首先，在启动 Tomcat 时，任何指定变量的传递方式都是相同的，可以传递到执行“start”或“run”命令中，但只有设定在 JAVA_OPTS 变量里的参数被传递到“stop”命令中。对于 Tomcat 运行过程，可能没什么区别，影响的是结束程序，而不是启动程序。 第二个区别是更微妙，其他应用程序也可以使用 JAVA_OPTS 变量，但只有在 Tomcat 中使用 CATALINA_OPTS 变量。如果你设置环境变量为只使用 Tomcat，最好你会建议使用 CATALINA_OPTS 变量，而如果你设置环境变量使用其它的 Java 应用程序，例如 JBoss，你应该把你的设置放在JAVA_OPTS 变量中。 2、JVM 参数属性32 位系统下 JVM 对内存的限制：不能突破 2GB ，那么这时你的 Tomcat 要优化，就要讲究点技巧了，而在 64 位操作系统上无论是系统内存还是 JVM 都没有受到 2GB 这样的限制。 针对于 JMX 远程监控也是在这里设置，以下为 64 位系统环境下的配置，内存加入的参数如下： 12345678910111213141516171819202122CATALINA_OPTS=&quot;-server -Xms6000M -Xmx6000M -Xss512k -XX:NewSize=2250M -XX:MaxNewSize=2250M -XX:PermSize=128M-XX:MaxPermSize=256M -XX:+AggressiveOpts -XX:+UseBiasedLocking -XX:+DisableExplicitGC -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:MaxTenuringThreshold=31 -XX:+CMSParallelRemarkEnabled -XX:+UseCMSCompactAtFullCollection -XX:LargePageSizeInBytes=128m -XX:+UseFastAccessorMethods -XX:+UseCMSInitiatingOccupancyOnly-Duser.timezone=Asia/Shanghai -Djava.awt.headless=true&quot; 为了看着方便，将每个参数单独写一行。上面参数好多啊，可能有人写到现在都没见过一个在 Tomcat 的启动命令里加了这么多参数，当然，这些参数只是示例，不一定适合你，尤其是参数后的 value（值）是需要根据你自己的实际情况来设置的。 上述这样的配置，基本上可以达到： 系统响应时间增快；JVM回收速度增快同时又不影响系统的响应率；JVM内存最大化利用；线程阻塞情况最小化。 JVM 常用参数详解：-server：一定要作为第一个参数，在多个 CPU 时性能佳，还有一种叫 -client 的模式，特点是启动速度比较快，但运行时性能和内存管理效率不高，通常用于客户端应用程序或开发调试，在 32 位环境下直接运行 Java 程序默认启用该模式。Server 模式的特点是启动速度比较慢，但运行时性能和内存管理效率很高，适用于生产环境，在具有 64 位能力的 JDK 环境下默认启用该模式，可以不配置该参数。 -Xms：表示 Java 初始化堆的大小，-Xms 与-Xmx 设成一样的值，避免 JVM 反复重新申请内存，导致性能大起大落，默认值为物理内存的 1/64，默认（MinHeapFreeRatio参数可以调整）空余堆内存小于 40% 时，JVM 就会增大堆直到 -Xmx 的最大限制。 -Xmx：表示最大 Java 堆大小，当应用程序需要的内存超出堆的最大值时虚拟机就会提示内存溢出，并且导致应用服务崩溃，因此一般建议堆的最大值设置为可用内存的最大值的80%。如何知道我的 JVM 能够使用最大值，使用 java -Xmx512M -version 命令来进行测试，然后逐渐的增大 512 的值,如果执行正常就表示指定的内存大小可用，否则会打印错误信息，默认值为物理内存的 1/4，默认（MinHeapFreeRatio参数可以调整）空余堆内存大于 70% 时，JVM 会减少堆直到-Xms 的最小限制。 -Xss：表示每个 Java 线程堆栈大小，JDK 5.0 以后每个线程堆栈大小为 1M，以前每个线程堆栈大小为 256K。根据应用的线程所需内存大小进行调整，在相同物理内存下，减小这个值能生成更多的线程，但是操作系统对一个进程内的线程数还是有限制的，不能无限生成，经验值在 3000~5000 左右。一般小的应用， 如果栈不是很深， 应该是128k 够用的，大的应用建议使用 256k 或 512K，一般不易设置超过 1M，要不然容易出现out ofmemory。这个选项对性能影响比较大，需要严格的测试。 -XX:NewSize：设置新生代内存大小。 -XX:MaxNewSize：设置最大新生代新生代内存大小-XX:PermSize：设置持久代内存大小 -XX:MaxPermSize：设置最大值持久代内存大小，永久代不属于堆内存，堆内存只包含新生代和老年代。 -XX:+AggressiveOpts：作用如其名（aggressive），启用这个参数，则每当 JDK 版本升级时，你的 JVM 都会使用最新加入的优化技术（如果有的话）。 -XX:+UseBiasedLocking：启用一个优化了的线程锁，我们知道在我们的appserver，每个http请求就是一个线程，有的请求短有的请求长，就会有请求排队的现象，甚至还会出现线程阻塞，这个优化了的线程锁使得你的appserver内对线程处理自动进行最优调配。 -XX:+DisableExplicitGC：在 程序代码中不允许有显示的调用“System.gc()”。每次在到操作结束时手动调用 System.gc() 一下，付出的代价就是系统响应时间严重降低，就和关于 Xms，Xmx 里的解释的原理一样，这样去调用 GC 导致系统的 JVM 大起大落。 -XX:+UseConcMarkSweepGC：设置年老代为并发收集，即 CMS gc，这一特性只有 jdk1.5后续版本才具有的功能，它使用的是 gc 估算触发和 heap 占用触发。我们知道频频繁的 GC 会造面 JVM的大起大落从而影响到系统的效率，因此使用了 CMS GC 后可以在 GC 次数增多的情况下，每次 GC 的响应时间却很短，比如说使用了 CMSGC 后经过 jprofiler 的观察，GC 被触发次数非常多，而每次 GC 耗时仅为几毫秒。 -XX:+UseParNewGC：对新生代采用多线程并行回收，这样收得快，注意最新的 JVM 版本，当使用 -XX:+UseConcMarkSweepGC 时，-XX:UseParNewGC 会自动开启。因此，如果年轻代的并行 GC 不想开启，可以通过设置 -XX：-UseParNewGC 来关掉。 -XX:MaxTenuringThreshold：设置垃圾最大年龄。如果设置为0的话，则新生代对象不经过 Survivor 区，直接进入老年代。对于老年代比较多的应用（需要大量常驻内存的应用），可以提高效率。如果将此值设置为一 个较大值，则新生代对象会在 Survivor 区进行多次复制，这样可以增加对象在新生代的存活时间，增加在新生代即被回收的概率，减少Full GC的频率，这样做可以在某种程度上提高服务稳定性。该参数只有在串行 GC 时才有效，这个值的设置是根据本地的 jprofiler 监控后得到的一个理想的值，不能一概而论原搬照抄。 -XX:+CMSParallelRemarkEnabled：在使用 UseParNewGC 的情况下，尽量减少 mark 的时间。 -XX:+UseCMSCompactAtFullCollection：在使用 concurrent gc 的情况下，防止 memoryfragmention，对 live object 进行整理，使 memory 碎片减少。 -XX:LargePageSizeInBytes：指定 Java heap 的分页页面大小，内存页的大小不可设置过大， 会影响 Perm 的大小。 -XX:+UseFastAccessorMethods：使用 get，set 方法转成本地代码，原始类型的快速优化。-XX:+UseCMSInitiatingOccupancyOnly：只有在 oldgeneration 在使用了初始化的比例后 concurrent collector 启动收集。 -Duser.timezone=Asia/Shanghai：设置用户所在时区。-Djava.awt.headless=true：这个参数一般我们都是放在最后使用的，这全参数的作用是这样的，有时我们会在我们的 J2EE 工程中使用一些图表工具如：jfreechart，用于在 web 网页输出 GIF/JPG 等流，在 winodws 环境下，一般我们的 app server 在输出图形时不会碰到什么问题，但是在linux/unix 环境下经常会碰到一个 exception 导致你在 winodws 开发环境下图片显示的好好可是在 linux/unix 下却显示不出来，因此加上这个参数以免避这样的情况出现。 -Xmn：新生代的内存空间大小，注意：此处的大小是（eden+ 2 survivor space)。与 jmap -heap 中显示的 New gen 是不同的。整个堆大小 = 新生代大小 + 老生代大小 + 永久代大小。在保证堆大小不变的情况下，增大新生代后，将会减小老生代大小。此值对系统性能影响较大，Sun官方推荐配置为整个堆的 3/8。 -XX:CMSInitiatingOccupancyFraction：当堆满之后，并行收集器便开始进行垃圾收集，例如，当没有足够的空间来容纳新分配或提升的对象。对于 CMS 收集器，长时间等待是不可取的，因为在并发垃圾收集期间应用持续在运行（并且分配对象）。因此，为了在应用程序使用完内存之前完成垃圾收集周期，CMS 收集器要比并行收集器更先启动。因为不同的应用会有不同对象分配模式，JVM 会收集实际的对象分配（和释放）的运行时数据，并且分析这些数据，来决定什么时候启动一次 CMS 垃圾收集周期。这个参数设置有很大技巧，基本上满足(Xmx-Xmn)(100-CMSInitiatingOccupancyFraction)/100 &gt;= Xmn 就不会出现 promotion failed。例如在应用中 Xmx 是6000，Xmn 是 512，那么 Xmx-Xmn 是 5488M，也就是老年代有 5488M，CMSInitiatingOccupancyFraction=90 说明老年代到 90% 满的时候开始执行对老年代的并发垃圾回收（CMS），这时还 剩 10% 的空间是 548810% = 548M，所以即使 Xmn（也就是新生代共512M）里所有对象都搬到老年代里，548M 的空间也足够了，所以只要满足上面的公式，就不会出现垃圾回收时的 promotion failed，因此这个参数的设置必须与 Xmn 关联在一起。 -XX:+CMSIncrementalMode：该标志将开启 CMS 收集器的增量模式。增量模式经常暂停 CMS 过程，以便对应用程序线程作出完全的让步。因此，收集器将花更长的时间完成整个收集周期。因此，只有通过测试后发现正常 CMS 周期对应用程序线程干扰太大时，才应该使用增量模式。由于现代服务器有足够的处理器来适应并发的垃圾收集，所以这种情况发生得很少，用于但 CPU情况。 -XX:NewRatio：年轻代（包括 Eden 和两个 Survivor 区）与年老代的比值（除去持久代），-XX:NewRatio=4 表示年轻代与年老代所占比值为 1:4，年轻代占整个堆栈的 1/5，Xms=Xmx 并且设置了 Xmn 的情况下，该参数不需要进行设置。 -XX:SurvivorRatio：Eden 区与 Survivor 区的大小比值，设置为 8，表示 2 个 Survivor 区（JVM 堆内存年轻代中默认有 2 个大小相等的 Survivor 区）与 1 个 Eden 区的比值为 2:8，即 1 个 Survivor 区占整个年轻代大小的 1/10。 -XX:+UseSerialGC：设置串行收集器。 -XX:+UseParallelGC：设置为并行收集器。此配置仅对年轻代有效。即年轻代使用并行收集，而年老代仍使用串行收集。 -XX:+UseParallelOldGC：配置年老代垃圾收集方式为并行收集，JDK6.0 开始支持对年老代并行收集。 -XX:ConcGCThreads：早期 JVM 版本也叫-XX:ParallelCMSThreads，定义并发 CMS 过程运行时的线程数。比如 value=4 意味着 CMS 周期的所有阶段都以 4 个线程来执行。尽管更多的线程会加快并发 CMS 过程，但其也会带来额外的同步开销。因此，对于特定的应用程序，应该通过测试来判断增加 CMS 线程数是否真的能够带来性能的提升。如果还标志未设置，JVM 会根据并行收集器中的 -XX:ParallelGCThreads 参数的值来计算出默认的并行 CMS 线程数。 -XX:ParallelGCThreads：配置并行收集器的线程数，即：同时有多少个线程一起进行垃圾回收，此值建议配置与 CPU 数目相等。 -XX:OldSize：设置 JVM 启动分配的老年代内存大小，类似于新生代内存的初始大小 -XX:NewSize。 以上就是一些常用的配置参数，有些参数是可以被替代的，配置思路需要考虑的是 Java 提供的垃圾回收机制。虚拟机的堆大小决定了虚拟机花费在收集垃圾上的时间和频度。收集垃圾能够接受的速度和应用有关，应该通过分析实际的垃圾收集的时间和频率来调整。假如堆的大小很大，那么完全垃圾收集就会很慢，但是频度会降低。假如您把堆的大小和内存的需要一致，完全收集就很快，但是会更加频繁。调整堆大小的的目的是最小化垃圾收集的时间，以在特定的时间内最大化处理客户的请求。在基准测试的时候，为确保最好的性能，要把堆的大小设大，确保垃圾收集不在整个基准测试的过程中出现。 假如系统花费很多的时间收集垃圾，请减小堆大小。一次完全的垃圾收集应该不超过 3-5 秒。假如垃圾收集成为瓶颈，那么需要指定代的大小，检查垃圾收集的周详输出，研究垃圾收集参数对性能的影响。当增加处理器时，记得增加内存，因为分配能够并行进行，而垃圾收集不是并行的。 3、设置系统属性Tomcat 的语言编码，配置起来很慢，要经过多次设置才可以了，否则中文很有可能出现乱码情况。譬如汉字“中”，以 UTF-8 编码后得到的是 3 字节的值 %E4%B8%AD，然后通过 GET 或者 POST 方式把这 3 个字节提交到 Tomcat 容器，如果你不告诉 Tomcat 我的参数是用 UTF-8编码的，那么 Tomcat 就认为你是用 ISO-8859-1 来编码的，而 ISO8859-1（兼容 URI 中的标准字符集 US-ASCII）是兼容 ASCII 的单字节编码并且使用了单字节内的所有空间，因此 Tomcat 就以为你传递的用 ISO-8859-1 字符集编码过的 3 个字符，然后它就用 ISO-8859-1 来解码。 设置起来不难使用“ -D&lt;名称&gt;=&lt;值&gt; ”来设置系统属性： -Djavax.servlet.request.encoding=UTF-8-Djavax.servlet.response.encoding=UTF-8-Dfile.encoding=UTF-8-Duser.country=CN-Duser.language=zh 4、常见的 Java 内存溢出有以下三种（1） java.lang.OutOfMemoryError: Java heap space —- JVM Heap（堆）溢出JVM 在启动的时候会自动设置 JVM Heap 的值，其初始空间（即-Xms）是物理内存的1/64，最大空间（-Xmx）不可超过物理内存。可以利用 JVM提供的 -Xmn -Xms -Xmx 等选项可进行设置。Heap 的大小是 Young Generation 和 Tenured Generaion 之和。在 JVM 中如果 98％ 的时间是用于 GC，且可用的 Heap size 不足 2％ 的时候将抛出此异常信息。 解决方法：手动设置 JVM Heap（堆）的大小。 （2） java.lang.OutOfMemoryError: PermGen space —- PermGen space溢出。PermGen space 的全称是 Permanent Generation space，是指内存的永久保存区域。为什么会内存溢出，这是由于这块内存主要是被 JVM 存放Class 和 Meta 信息的，Class 在被 Load 的时候被放入 PermGen space 区域，它和存放 Instance 的 Heap 区域不同，sun 的 GC 不会在主程序运行期对 PermGen space 进行清理，所以如果你的 APP 会载入很多 CLASS 的话，就很可能出现 PermGen space 溢出。 解决方法： 手动设置 MaxPermSize 大小 （3） java.lang.StackOverflowError —- 栈溢出栈溢出了，JVM 依然是采用栈式的虚拟机，这个和 C 与 Pascal 都是一样的。函数的调用过程都体现在堆栈和退栈上了。调用构造函数的 “层”太多了，以致于把栈区溢出了。通常来讲，一般栈区远远小于堆区的，因为函数调用过程往往不会多于上千层，而即便每个函数调用需要 1K 的空间（这个大约相当于在一个 C 函数内声明了 256 个 int 类型的变量），那么栈区也不过是需要 1MB 的空间。通常栈的大小是 1－2MB 的。通常递归也不要递归的层次过多，很容易溢出。 解决方法：修改程序。 更多信息，请参考以下文章： JVM 垃圾回收调优总结http://developer.51cto.com/art/201201/312639.htm JVM调优总结：典型配置举例http://developer.51cto.com/art/201201/311739.htm JVM基础：JVM参数设置、分析http://developer.51cto.com/art/201201/312018.htm JVM 堆内存相关的启动参数：年轻代、老年代和永久代的内存分配http://www.2cto.com/kf/201409/334840.html Java 虚拟机–新生代与老年代GChttp://my.oschina.net/sunnywu/blog/332870 JVM（Java虚拟机）优化大全和案例实战http://blog.csdn.net/kthq/article/details/8618052 JVM内存区域划分Eden Space、Survivor Space、Tenured Gen，Perm Gen解释http://blog.chinaunix.net/xmlrpc.php?r=blog/article&amp;uid=29632145&amp;id=4616836","categories":[{"name":"Java","slug":"Java","permalink":"https://ldongxu.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://ldongxu.github.io/tags/Java/"},{"name":"Tomcat","slug":"Tomcat","permalink":"https://ldongxu.github.io/tags/Tomcat/"},{"name":"JVM","slug":"JVM","permalink":"https://ldongxu.github.io/tags/JVM/"}]},{"title":"Java内存模型","slug":"Java内存模型","date":"2016-04-18T02:09:40.000Z","updated":"2018-07-06T12:33:08.041Z","comments":true,"path":"2016/04/18/Java内存模型/","link":"","permalink":"https://ldongxu.github.io/2016/04/18/Java内存模型/","excerpt":"&emsp;Java内存模型即Java Memory Model，简称JMM。JMM定义了Java 虚拟机(JVM)在计算机内存(RAM)中的工作方式。JVM是整个计算机虚拟模型，所以JMM是隶属于JVM的。&emsp;Java线程之间的通信采用的是共享内存模型，这里提到的共享内存模型指的就是Java内存模型(简称JMM)，JMM决定一个线程对共享变量的写入何时对另一个线程可见。从抽象的角度来看，JMM定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存（main memory）中，每个线程都有一个私有的本地内存（local memory），本地内存中存储了该线程以读/写共享变量的副本。本地内存是JMM的一个抽象概念，并不真实存在。它涵盖了缓存，写缓冲区，寄存器以及其他的硬件和编译器优化。","text":"&emsp;Java内存模型即Java Memory Model，简称JMM。JMM定义了Java 虚拟机(JVM)在计算机内存(RAM)中的工作方式。JVM是整个计算机虚拟模型，所以JMM是隶属于JVM的。&emsp;Java线程之间的通信采用的是共享内存模型，这里提到的共享内存模型指的就是Java内存模型(简称JMM)，JMM决定一个线程对共享变量的写入何时对另一个线程可见。从抽象的角度来看，JMM定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存（main memory）中，每个线程都有一个私有的本地内存（local memory），本地内存中存储了该线程以读/写共享变量的副本。本地内存是JMM的一个抽象概念，并不真实存在。它涵盖了缓存，写缓冲区，寄存器以及其他的硬件和编译器优化。 JVM对Java内存模型的实现在JVM内部，Java内存模型把内存分成了两部分：线程栈区和堆区，下图展示了Java内存模型在JVM中的逻辑视图：JVM中运行的每个线程都拥有自己的线程栈，线程栈包含了当前线程执行的方法调用相关信息，我们也把它称作调用栈。随着代码的不断执行，调用栈会不断变化。线程栈还包含了当前方法的所有本地变量信息。一个线程只能读取自己的线程栈，也就是说，线程中的本地变量对其它线程是不可见的。即使两个线程执行的是同一段代码，它们也会各自在自己的线程栈中创建本地变量，因此，每个线程中的本地变量都会有自己的版本。所有原始类型(boolean,byte,short,char,int,long,float,double)的本地变量都直接保存在线程栈当中，对于它们的值各个线程之间都是独立的。对于原始类型的本地变量，一个线程可以传递一个副本给另一个线程，当它们之间是无法共享的。堆区包含了Java应用创建的所有对象信息，不管对象是哪个线程创建的，其中的对象包括原始类型的封装类（如Byte、Integer、Long等等）。不管对象是属于一个成员变量还是方法中的本地变量，它都会被存储在堆区。下图展示了调用栈和本地变量都存储在栈区，对象都存储在堆区：一个本地变量如果是原始类型，那么它会被完全存储到栈区。一个本地变量也有可能是一个对象的引用，这种情况下，这个本地引用会被存储到栈中，但是对象本身仍然存储在堆区。对于一个对象的成员方法，这些方法中包含本地变量，仍需要存储在栈区，即使它们所属的对象在堆区。对于一个对象的成员变量，不管它是原始类型还是包装类型，都会被存储到堆区。Static类型的变量以及类本身相关信息都会随着类本身存储在堆区。堆中的对象可以被多线程共享。如果一个线程获得一个对象的应用，它便可访问这个对象的成员变量。如果两个线程同时调用了同一个对象的同一个方法，那么这两个线程便可同时访问这个对象的成员变量，但是对于本地变量，每个线程都会拷贝一份到自己的线程栈中。下图展示了上面描述的过程: 硬件内存架构Java内存模型和硬件架构之间的桥接共享对象的可见性竞争现象支持Java内存模型的基础原理指令重排序数据依赖性内存屏障","categories":[{"name":"Java","slug":"Java","permalink":"https://ldongxu.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://ldongxu.github.io/tags/Java/"},{"name":"JMM","slug":"JMM","permalink":"https://ldongxu.github.io/tags/JMM/"}]},{"title":"静态工具类获取Spring IoC管理的bean组件","slug":"静态工具类获取Spring-IoC管理的bean组件","date":"2016-03-25T06:05:03.000Z","updated":"2018-07-06T12:33:08.044Z","comments":true,"path":"2016/03/25/静态工具类获取Spring-IoC管理的bean组件/","link":"","permalink":"https://ldongxu.github.io/2016/03/25/静态工具类获取Spring-IoC管理的bean组件/","excerpt":"一般情况我们通过@Resource或者@Autowired或者applicationContext.xml配置来注入所需的bean组件。但是，有的时候我们在一些静态工具类中或者组件里要通过名称去获得spring管理的bean。","text":"一般情况我们通过@Resource或者@Autowired或者applicationContext.xml配置来注入所需的bean组件。但是，有的时候我们在一些静态工具类中或者组件里要通过名称去获得spring管理的bean。 1、实现ApplicationContextAware接口1234567891011121314151617181920212223242526package com.ldongxu.common;import org.springframework.beans.BeansException;import org.springframework.context.ApplicationContext;import org.springframework.context.ApplicationContextAware;public class SpringUtil implements ApplicationContextAware &#123; private static ApplicationContext applicationContext = null; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; if (SpringUtil.applicationContext == null) &#123; SpringUtil.applicationContext = applicationContext; System.out.println(\"========ApplicationContext配置成功,在普通类中可以通过调用SpringUtil.getApplicationContext()获取applicationContext对象,applicationContext=\" + applicationContext + \"========\"); &#125; &#125; public static ApplicationContext getApplicationContext() &#123; return applicationContext; &#125; public static Object getBean(String name) &#123; return applicationContext.getBean(name); &#125;&#125; 2、在Spring的配置文件中声明添加此工具类1&lt;bean class=&quot;com.ldongxu.common.SpringUtil&quot;&gt;&lt;/bean&gt; 注意：springUtil只能获取到和它定义在同一个上下文里的bean，换句话说，如果想用springUtil获取某个bean，那么这个bean必须和springUtil同在一个上下文中，即声明放在同一个xml文件里。","categories":[{"name":"Java","slug":"Java","permalink":"https://ldongxu.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://ldongxu.github.io/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"https://ldongxu.github.io/tags/Spring/"}]},{"title":"解决Ajax跨域访问－JSONP","slug":"解决Ajax跨域访问－JSONP","date":"2016-02-24T02:03:59.000Z","updated":"2018-07-06T12:33:08.044Z","comments":true,"path":"2016/02/24/解决Ajax跨域访问－JSONP/","link":"","permalink":"https://ldongxu.github.io/2016/02/24/解决Ajax跨域访问－JSONP/","excerpt":"同源策略首先我们来了解一下浏览器的同源策略，浏览器为了安全都会遵循同源策略。同源策略（Same origin policy）是一种约定，它是浏览器最核心也最基本的安全功能，如果缺少了同源策略，则浏览器的正常功能可能都会受到影响。可以说Web是构建在同源策略基础之上的，浏览器只是针对同源策略的一种实现。","text":"同源策略首先我们来了解一下浏览器的同源策略，浏览器为了安全都会遵循同源策略。同源策略（Same origin policy）是一种约定，它是浏览器最核心也最基本的安全功能，如果缺少了同源策略，则浏览器的正常功能可能都会受到影响。可以说Web是构建在同源策略基础之上的，浏览器只是针对同源策略的一种实现。 同源策略，它是由Netscape提出的一个著名的安全策略。现在所有支持JavaScript 的浏览器都会使用这个策略。所谓同源是指，域名，协议，端口相同。当一个浏览器的两个tab页中分别打开来 百度和谷歌的页面当浏览器的百度tab页执行一个脚本的时候会检查这个脚本是属于哪个页面的，即检查是否同源，只有和百度同源的脚本才会被执行。如果非同源，那么在请求数据时，浏览器会在控制台中报一个异常，提示拒绝访问。 会出现跨域问题的几种情况： Ajax实现跨域1. 通过代理方案实现跨域这种方式是通过后台(ASP、PHP、Java、ASP.NET)获取其他域名下的内容，然后再把获得内容返回到前端，这样因为在同一个域名下，所以就不会出现跨域的问题。 代理实现比较麻烦，但使用最广泛，任何支持AJAX的浏览器都可以使用这种方式。 2. JSONP JSONP是JSON with Padding的略称。它是一个非官方的协议，它允许在服务器端集成Script tags返回至客户端，通过javascript callback的形式实现跨域访问（这仅仅是JSONP简单的实现形式）。 模拟一个非同源的环境，假设A程序是localhost:20001,B程序是localhost:20002(域名相同但端口号不同)，做一个小示例。在A程序添加sample.html和test.js，sample.html代码如下：123456789&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\"&gt;&lt;html xmlns=\"http://www.w3.org/1999/xhtml\" &gt;&lt;head&gt;&lt;title&gt;test&lt;/title&gt;&lt;script type=\"text/javascript\" src=\"test.js\"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt; test.js代码如下：1alert(\"success\"); 打开localhost:20001/sample.html后会跳出”success”这样的这样的信息框，这似乎并不能说明什么， 跨域问题到底怎么解决呢？好，现在我们模拟下非同源的环境,将我们的之前的test.js文件从A程序中移除然后拷贝到B程序中，因为test.js文件在B程序上了，所以testx.js在sample.html里的引用就应该是：1&lt;script type=&quot;text/javascript&quot; src=&quot;http://localhost:20002/test.js&quot;&gt;&lt;/script&gt; 请保持AB两个Web程序的运行状态，当你再次刷新localhost:20001/sample.html的时候，和原来一样跳出了”success”的对话框，是的，成功访问到了非同源的localhost:20002/test.js这个所谓的远程服务了。到了这一步，相信大家应该已经大概明白如何跨域访问了的原理了。 &lt;script&gt;标签的src属性并不被同源策略所约束，所以可以获取任何服务器上脚本并执行。 JSONP的定义说明中讲到了javascript callback的形式。那我们就来修改下代码，如何实现JSONP的javascript callback的形式。程序A中sample.html的代码:123456789101112131415&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd&quot;&gt;&lt;html xmlns=&quot;http://www.w3.org/1999/xhtml&quot; &gt;&lt;head&gt;&lt;title&gt;test&lt;/title&gt;&lt;script type=&quot;text/javascript&quot;&gt; //回调函数 function callback(data) &#123; alert(data.message); &#125; &lt;/script&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;http://localhost:20002/test.js&quot;&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt; 程序B中test.js的代码：12//调用callback函数，并以json数据形式作为阐述传递，完成回调callback(&#123;message:&quot;success&quot;&#125;); 这其实就是JSONP的简单实现模式，或者说是JSONP的原型：创建一个回调函数，然后在远程服务上调用这个函数并且将JSON 数据形式作为参数传递，完成回调。（也就是类似于返回一个带结果数据的js function）。 一般情况下，我们希望这个&lt;script&gt;标签引用能够动态的调用，而不是像上面因为固定在html里面所以没等页面显示就执行了，很不灵活。我们可以通过javascript动态的创建script标签，这样我们就可以灵活调用远程服务了。比如程序A中sample.html的部分代码可以修改为：12345678910111213141516&lt;script type=&quot;text/javascript&quot;&gt; function callback(data) &#123; alert(data.message); &#125; //添加&lt;script&gt;标签的方法 function addScriptTag(src)&#123; var script = document.createElement(&apos;script&apos;); script.setAttribute(&quot;type&quot;,&quot;text/javascript&quot;); script.src = src; document.body.appendChild(script); &#125; window.onload = function()&#123; addScriptTag(&quot;http://localhost:20002/test.js&quot;); &#125;&lt;/script&gt; 程序B的test.js代码不变，我们再执行下程序，是不是和原来的一样呢。如果我们再想调用另一个远程服务的话，只要添加addScriptTag方法，传入远程服务的src值就可以了。这里说明下为什么要将addScriptTag方法放入到window.onload的方法里，原因是addScriptTag方法中有句document.body.appendChild(script);，这个script标签是被添加到body里的，由于我们写的javascript代码是在head标签中，document.body还没有初始化完毕呢，所以我们要通过window.onload方法先初始化页面，这样才不会出错。 上面的例子是最简单的JSONP的实现模型，不过它还算不上一个真正的JSONP服务。我们来看一下真正的JSONP服务是怎么样的，比如Google的ajax搜索接口：http://ajax.googleapis.com/ajax/services/search/web?v=1.0&amp;q=?&amp;callback=?。q=?这个问号是表示你要搜索的内容，最重要的是第二个callback=?这个是正如其名表示回调函数的名称，也就是将你自己在客户端定义的回调函数的函数名传送给服务端，服务端则会返回以你定义的回调函数名的方法，将获取的json数据传入这个方法完成回调。 看看实现代码吧：1234567891011121314151617181920&lt;script type=&quot;text/javascript&quot;&gt; //添加&lt;script&gt;标签的方法 function addScriptTag(src)&#123; var script = document.createElement(&apos;script&apos;); script.setAttribute(&quot;type&quot;,&quot;text/javascript&quot;); script.src = src; document.body.appendChild(script); &#125; window.onload = function()&#123; //搜索apple，将自定义的回调函数名result传入callback参数中 addScriptTag(&quot;http://ajax.googleapis.com/ajax/services/search/web?v=1.0&amp;q=apple&amp;callback=result&quot;); &#125; //自定义的回调函数result function result(data) &#123; //我们就简单的获取apple搜索结果的第一条记录中url数据 alert(data.responseData.results[0].unescapedUrl); &#125;&lt;/script&gt; 像Google这样的JSONP服务还有很多： Digg API：来自 Digg 的头条新闻：http://services.digg.com/stories/top?appkey=http%3A%2F%2Fmashup.com&amp;type=javascript&amp;callback=? Geonames API：邮编的位置信息：http://www.geonames.org/postalCodeLookupJSON?postalcode=10504&amp;country=US&amp;callback=? Flickr JSONP API：载入最新猫的图片：http://api.flickr.com/services/feeds/photos_public.gne?tags=cat&amp;tagmode=any&amp;format=json&amp;jsoncallback=? Yahoo Local Search API：在邮编为 10504 的地区搜索比萨：http://local.yahooapis.com/LocalSearchService/V3/localSearch?appid=YahooDemo&amp;query=pizza&amp;zip=10504&amp;results=2&amp;output=json&amp;callback=? 接下来我们自己来创建一个简单的远程服务，实现和上面一样的JSONP服务。还是利用Web程序A和程序B来做演示，这次我们在程序B上创建一个MyService.java文件。12345678910@Controllerpublic class MyService &#123; @RequestMapping(\"/myService\") public String ProcessRequest(String callback)&#123; String jsonDataStr = \"&#123;\\\"name\\\":\\\"chopper\\\",\\\"sex\\\":\\\"man\\\"&#125;\"; return callback+\"(\"+jsonDataStr+\")\"; &#125; &#125; 程序A的sample.html代码中的调用：123456789101112131415161718&lt;script type=&quot;text/javascript&quot;&gt; function addScriptTag(src)&#123; var script = document.createElement(&apos;script&apos;); script.setAttribute(&quot;type&quot;,&quot;text/javascript&quot;); script.src = src; document.body.appendChild(script); &#125; window.onload = function()&#123; //调用远程服务 addScriptTag(&quot;http://localhost:20002/myService?callback=person&quot;); &#125; //回调函数person function person(data) &#123; alert(data.name + &quot; is a &quot; + data.sex); &#125;&lt;/script&gt; 这就完成了一个最基本的JSONP服务调用了。 下面我们来了解下jQuery是如何调用JSONP的。jQuery框架也当然支持JSONP，可以使用$.getJSON(url,[data],[callback])方法(详细可以参考http://api.jquery.com/jQuery.getJSON/)。那我们就来修改下程序A的代码，改用jQuery的getJSON方法来实现(下面的例子没用用到向服务传参，所以只写了getJSON(url,[callback]))：123456&lt;script type=&quot;text/javascript&quot; src=&quot;http://code.jquery.com/jquery-latest.js&quot;&gt;&lt;/script&gt;&lt;script type=&quot;text/javascript&quot;&gt; $.getJSON(&quot;http://localhost:20002/myService?callback=?&quot;,function(data)&#123; alert(data.name + &quot; is a a&quot; + data.sex); &#125;);&lt;/script&gt; 结果是一样的，要注意的是在url的后面必须添加一个callback参数，这样getJSON方法才会知道是用JSONP方式去访问服务，callback后面的那个问号是内部自动生成的一个回调函数名。这个函数名大家可以debug一下看看，比如jQuery17207481773362960666_1332575486681。 当然，假如说我们想指定自己的回调函数名，或者说服务上规定了固定回调函数名该怎么办呢？我们可以使用$.ajax方法来实现(参数较多，详细可以参考http://api.jquery.com/jQuery.ajax)。先来看看如何实现吧：1234567891011&lt;script type=&quot;text/javascript&quot; src=&quot;http://code.jquery.com/jquery-latest.js&quot;&gt;&lt;/script&gt;&lt;script type=&quot;text/javascript&quot;&gt; $.ajax(&#123; url:&quot;http://localhost:20002/myService?callback=?&quot;, dataType:&quot;jsonp&quot;, jsonpCallback:&quot;person&quot;, success:function(data)&#123; alert(data.name + &quot; is a a&quot; + data.sex); &#125; &#125;);&lt;/script&gt; 没错，jsonpCallback就是可以指定我们自己的回调方法名person，远程服务接受callback参数的值就不再是自动生成的回调名，而是person。dataType是指定按照JSOPN方式访问远程服务。 利用jQuery可以很方便的实现JSONP来进行跨域访问。 下面给出个栗子一.客户端 1234567891011121314151617181920212223242526272829303132333435&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\"&gt; &lt;html&gt; &lt;head&gt; &lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\"&gt; &lt;title&gt;Insert title here&lt;/title&gt; &lt;script type=\"text/javascript\" src=\"resource/js/jquery-1.7.2.js\"&gt;&lt;/script&gt; &lt;/head&gt; &lt;script type=\"text/javascript\"&gt; $(function()&#123; /* //简写形式，效果相同 $.getJSON(\"http://app.example.com/base/json.do?sid=1494&amp;busiId=101&amp;jsonpCallback=?\", function(data)&#123; $(\"#showcontent\").text(\"Result:\"+data.result) &#125;); */ $.ajax(&#123; type : \"get\", async:false, url : \"http://app.example.com/base/json.do?sid=1494&amp;busiId=101\", dataType : \"jsonp\",//数据类型为jsonp jsonp: \"jsonpCallback\",//服务端用于接收callback调用的function名的参数 success : function(data)&#123; $(\"#showcontent\").text(\"Result:\"+data.result) &#125;, error:function()&#123; alert('fail'); &#125; &#125;); &#125;); &lt;/script&gt; &lt;body&gt; &lt;div id=\"showcontent\"&gt;Result:&lt;/div&gt; &lt;/body&gt; &lt;/html&gt; 二.服务器端 Java代码1234567891011121314151617181920212223242526272829303132import java.io.IOException; import java.io.PrintWriter; import java.util.HashMap; import java.util.Map; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; import net.sf.json.JSONObject; import org.springframework.stereotype.Controller; import org.springframework.web.bind.annotation.RequestMapping; @Controller public class ExchangeJsonController &#123; @RequestMapping(\"/base/json.do\") public void exchangeJson(HttpServletRequest request,HttpServletResponse response) &#123; try &#123; response.setContentType(\"text/plain\"); response.setHeader(\"Pragma\", \"No-cache\"); response.setHeader(\"Cache-Control\", \"no-cache\"); response.setDateHeader(\"Expires\", 0); Map&lt;String,String&gt; map = new HashMap&lt;String,String&gt;(); map.put(\"result\", \"content\"); PrintWriter out = response.getWriter(); JSONObject resultJSON = JSONObject.fromObject(map); //根据需要拼装json String jsonpCallback = request.getParameter(\"jsonpCallback\");//客户端请求参数 out.println(jsonpCallback+\"(\"+resultJSON.toString(1,1)+\")\");//返回jsonp格式数据 out.flush(); out.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;","categories":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://ldongxu.github.io/categories/JavaScript/"}],"tags":[{"name":"Ajax","slug":"Ajax","permalink":"https://ldongxu.github.io/tags/Ajax/"},{"name":"JSONP","slug":"JSONP","permalink":"https://ldongxu.github.io/tags/JSONP/"}]},{"title":"在同一个git Repository备份hexo文章及配置","slug":"在同一个git-Repository备份hexo文章及配置","date":"2016-01-02T10:10:33.000Z","updated":"2018-07-06T12:33:08.043Z","comments":true,"path":"2016/01/02/在同一个git-Repository备份hexo文章及配置/","link":"","permalink":"https://ldongxu.github.io/2016/01/02/在同一个git-Repository备份hexo文章及配置/","excerpt":"使用场景使用 Hexo 的一键发布文章很方便，但是有多个地点需要同步文章的时候就麻烦了。因为GitHub的repo上 只有Hexo 编译好的html文件，并没有Hexo的source文件（也就是文章）。如果需要在不同地点进行文章发布的话，就没有办法完成了（先不考虑草稿的事）所以，我们需要在其他repo进行文章的备份。","text":"使用场景使用 Hexo 的一键发布文章很方便，但是有多个地点需要同步文章的时候就麻烦了。因为GitHub的repo上 只有Hexo 编译好的html文件，并没有Hexo的source文件（也就是文章）。如果需要在不同地点进行文章发布的话，就没有办法完成了（先不考虑草稿的事）所以，我们需要在其他repo进行文章的备份。参考链接：http://www.jianshu.com/p/f746f8f7b32d 操作步骤上传操作进入 Hexo 所在的文件夹。打开 git bash 窗口，进行初始化repo：1git init 完成之后，添加修改的文件，本来 Hexo 就自带了 .gitignore 文件，需要忽略的文件 都已经默认配置好了。接下来进行第一次提交。当然了，git流程还是要走正确的，首先应该是add：(.的意思将所有文件进行添加)1git add . 然后commit：1git commit -m &quot;commit first time&quot; 提交成功之后，接下来就是 push 到github了。我们先把本地这个文件夹 映射到 远程 repo 上：1git remote add origin https://github.com/your-name/your-name.github.io.git 接下来就是把刚刚的提交 push 上去。关键点到了：Hexo 部署的 page 是在 master 上的，如果我们push 到 master 分支上的话，虽然程序还能运行，但是目录结构就会变得很乱了。 我们的做法是：把这些源文件（包括文章和配置）push到另外一个分支中。 怎么操作呢？ 1. 先新建一个分支名字叫 source：1git branch source 然后把刚刚的东西全部 push 到 source 分支上：1git push -u origin source 输入账号密码后上传，一会就成功了。 去 GitHub 上的 repo 看一下，有两个分支：一个是 master,里面的内容是 Hexo 生成了 page 页面；一个是 source, 里面的内容是我们的文章还有 Hexo 的配置等源文件。 这样的话，不管在什么地方都可以进行最新文章的获取和继续操作了。 当然了，修改了文章或者其他东西，在 deploy 前还是先 commit 和push 一下哦。记得：所有的本地操作都在 source 分支里面。 下载操作现在我们切换视觉到 一台新的电脑上，在这台电脑上没有 Node.js,没有 Hexo，没有 Git。 先安装必要的程序 node.js 和 git，过程不再赘述 把原来的文章下载下来 配置 git ssh key，你才拥有从这台电脑发布文章的权利（请不要在公共电脑操作） 然后就是走 Hexo 的发布流程，也就是上面的上传操作了 具体操作如下 1.把文章下载下来 找到自己喜欢的路径，新建一个文件夹，命名随意，自己认识就好打开 git bash1git clone xxxxxxxxx.xx (输入你的 github page 的 repo 地址) 等待下载完成之后，默认的分支是 master，master分支是 Hexo 编译之后的 网站程序，我们的文章在 source 分支内1git checkout source 这个时候文件夹内的内容已经是我们的博客源文件（包括文章和配置） 2.配置 git ssh key 还是在当前的 git bash 界面，打开 ssh-key 所在文件夹：1cd ~/.ssh 生成 ssh-key：1ssh-keygen -t rsa -C &quot;your_email@youremail.com&quot; 弹出一下提问，我们不修改生成路径，不设置密码短语，直接回车。1.找到.ssh文件夹，用文本编辑器打开“id_rsa.pub”文件，复制内容到剪贴板。注意：最后的空格不需要复制到（可能会引起一些问题）。2.然后就是去 github setting 里面设置 ssh-key 了，打开 https://github.com/settings/ssh，点击 Add SSH Key 按钮，粘贴进去保存即可。 配置完成之后，测试一下1ssh -T git@github.com 如果返回 Hello (username 表示你的用户名)，表示成功 3.配置 Hexo 程序了 安装 hexo:12npm install hexo-cli -gnpm install hexo --save 检查 hexo 是否安装成功：1hexo -v 这个时候就不做初始化了. 4.自动安装需要的组件 1npm install 安装 git 部署的插件：1npm install hexo-deployer-git --save 操作完成，现在这台新电脑 就跟原来那台电脑一样操作就可以发布文章了。","categories":[{"name":"Hexo博客","slug":"Hexo博客","permalink":"https://ldongxu.github.io/categories/Hexo博客/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://ldongxu.github.io/tags/Hexo/"}]},{"title":"Hello World","slug":"hello-world","date":"2016-01-01T11:10:33.000Z","updated":"2018-07-06T12:33:08.043Z","comments":true,"path":"2016/01/01/hello-world/","link":"","permalink":"https://ldongxu.github.io/2016/01/01/hello-world/","excerpt":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}